{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "32f9f688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Core_Game_Parts import *\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4d3f67ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_expert_data(filename=\"pretrain_data.npy\"):\n",
    "    \"\"\"\n",
    "    Run the simulation manually and save state-action pairs.\n",
    "    \"\"\"\n",
    "    # Force a display window to open for manual play\n",
    "    os.environ[\"SDL_VIDEODRIVER\"] = \"windows\"\n",
    "    \n",
    "    pygame.init()\n",
    "    screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "    clock = pygame.time.Clock()\n",
    "    track_surface = pygame.image.load(TRACK_IMAGE_PATH).convert()\n",
    "    car = Car(CAR_IMAGE_PATH, DEFAULT_START_X, DEFAULT_START_Y, angle=DEFAULT_START_ANGLE)\n",
    "    \n",
    "    driving_data = []\n",
    "    running = True\n",
    "    print(\"Starting data collection. Drive 3-5 clean laps. Press ESC or close window to finish.\")\n",
    "\n",
    "    while running:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT or (event.type == pygame.KEYDOWN and event.key == pygame.K_ESCAPE):\n",
    "                running = False\n",
    "        \n",
    "        keys = pygame.key.get_pressed()\n",
    "        action = None\n",
    "        # Map keys to the agent's actions (0: Left, 1: Right, 2: Brake)\n",
    "        if keys[pygame.K_LEFT] or keys[pygame.K_a]:  action = 0\n",
    "        elif keys[pygame.K_RIGHT] or keys[pygame.K_d]: action = 1\n",
    "        elif keys[pygame.K_DOWN] or keys[pygame.K_s]:  action = 2\n",
    "\n",
    "        distances, _ = ray_casting(car, track_surface)\n",
    "        normalized_speed = car.speed / MAX_SPEED\n",
    "        state = np.array(distances + [normalized_speed])\n",
    "        \n",
    "        if action is not None:\n",
    "            driving_data.append([state, action])\n",
    "\n",
    "        # Standard manual driving physics\n",
    "        if keys[pygame.K_UP] or keys[pygame.K_w]: car.speed += ACCELERATION\n",
    "        if car.speed > 0:\n",
    "            speed_factor = car.speed / MAX_SPEED\n",
    "            turn = MAX_TURN_ANGLE - (speed_factor) * (MAX_TURN_ANGLE - MIN_TURN_ANGLE)\n",
    "            if keys[pygame.K_LEFT] or keys[pygame.K_a]: car.angle += turn\n",
    "            if keys[pygame.K_RIGHT] or keys[pygame.K_d]: car.angle -= turn\n",
    "        if keys[pygame.K_DOWN] or keys[pygame.K_s]: car.speed -= BRAKE_FORCE\n",
    "        car.speed -= FRICTION\n",
    "        car.speed = max(0, min(car.speed, MAX_SPEED))\n",
    "        car.move()\n",
    "\n",
    "        screen.blit(track_surface, (0, 0)); car.draw(screen); pygame.display.update(); clock.tick(60)\n",
    "\n",
    "    pygame.quit()\n",
    "    \n",
    "    if driving_data:\n",
    "        print(f\"Saving {len(driving_data)} data points to {filename}...\")\n",
    "        driving_data_array = np.array(driving_data, dtype=object)\n",
    "        np.save(filename, driving_data_array, allow_pickle=True)\n",
    "        print(\"Save complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8cb250a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    \"\"\"Builds the neural network model.\"\"\"\n",
    "    net = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(4,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(3, activation='softmax') # Softmax is better for imitation learning\n",
    "    ])\n",
    "    net.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return net\n",
    "\n",
    "def pretrain_agent(data_path=\"pretrain_data.npy\", weights_path=\"pretrained.weights.h5\"):\n",
    "    \"\"\"\n",
    "    Trains a model on the expert data using supervised learning.\n",
    "    \"\"\"\n",
    "    print(\"Loading expert data...\")\n",
    "    expert_data = np.load(data_path, allow_pickle=True)\n",
    "    \n",
    "    states = np.array([item[0] for item in expert_data])\n",
    "    actions = np.array([item[1] for item in expert_data])\n",
    "    \n",
    "    # Convert actions to one-hot encoding (e.g., 0 -> [1,0,0], 1 -> [0,1,0])\n",
    "    actions_one_hot = to_categorical(actions, num_classes=3)\n",
    "    \n",
    "    print(f\"Data loaded. Training on {len(states)} samples...\")\n",
    "    ai_model = model()\n",
    "    \n",
    "    ai_model.fit(states, actions_one_hot, epochs=15, batch_size=64, validation_split=0.1, shuffle=True)\n",
    "    \n",
    "    print(f\"Pre-training complete. Saving weights to {weights_path}...\")\n",
    "    ai_model.save_weights(weights_path)\n",
    "    print(\"Weights saved!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ad86c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_imitation_model(data_path=\"pretrain_data.npy\", weights_path=\"final_imitation.weights.h5\"):\n",
    "    print(\"Loading expert data...\")\n",
    "    expert_data = np.load(data_path, allow_pickle=True)\n",
    "    \n",
    "    states = np.array([item[0] for item in expert_data])\n",
    "    actions = np.array([item[1] for item in expert_data])\n",
    "    actions_one_hot = to_categorical(actions, num_classes=3)\n",
    "    \n",
    "    print(f\"Data loaded. Training on {len(states)} samples...\")\n",
    "    \n",
    "    # Define the model for classification\n",
    "    imitation_model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(4,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(3, activation='softmax') # Softmax for predicting the probability of each action\n",
    "    ])\n",
    "    imitation_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model to imitate\n",
    "    imitation_model.fit(states, actions_one_hot, epochs=25, batch_size=64, validation_split=0.1, shuffle=True)\n",
    "    \n",
    "    print(f\"Training complete. Saving final weights to {weights_path}...\")\n",
    "    imitation_model.save_weights(weights_path)\n",
    "    print(\"Final weights saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2790c5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data collection. Drive 3-5 clean laps. Press ESC or close window to finish.\n",
      "Saving 875 data points to pretrain_data.npy...\n",
      "Save complete!\n",
      "Loading expert data...\n",
      "Data loaded. Training on 875 samples...\n",
      "Epoch 1/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5527 - loss: 2.7468 - val_accuracy: 0.7273 - val_loss: 0.4791\n",
      "Epoch 2/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7268 - loss: 0.8147 - val_accuracy: 0.5909 - val_loss: 0.8250\n",
      "Epoch 3/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7840 - loss: 0.6394 - val_accuracy: 0.6818 - val_loss: 0.5410\n",
      "Epoch 4/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7726 - loss: 0.4849 - val_accuracy: 0.7273 - val_loss: 0.5229\n",
      "Epoch 5/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7649 - loss: 0.5120 - val_accuracy: 0.7159 - val_loss: 0.5291\n",
      "Epoch 6/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7776 - loss: 0.5213 - val_accuracy: 0.7955 - val_loss: 0.4872\n",
      "Epoch 7/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7764 - loss: 0.4468 - val_accuracy: 0.7159 - val_loss: 0.5434\n",
      "Epoch 8/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7903 - loss: 0.4298 - val_accuracy: 0.6818 - val_loss: 0.5151\n",
      "Epoch 9/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8043 - loss: 0.4036 - val_accuracy: 0.6705 - val_loss: 0.5206\n",
      "Epoch 10/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8145 - loss: 0.3961 - val_accuracy: 0.7500 - val_loss: 0.4892\n",
      "Epoch 11/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7942 - loss: 0.4307 - val_accuracy: 0.6818 - val_loss: 0.5393\n",
      "Epoch 12/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8158 - loss: 0.3903 - val_accuracy: 0.7159 - val_loss: 0.5118\n",
      "Epoch 13/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8005 - loss: 0.4005 - val_accuracy: 0.6932 - val_loss: 0.5195\n",
      "Epoch 14/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8132 - loss: 0.3997 - val_accuracy: 0.5909 - val_loss: 0.6066\n",
      "Epoch 15/15\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8272 - loss: 0.3793 - val_accuracy: 0.5909 - val_loss: 0.6129\n",
      "Pre-training complete. Saving weights to pretrained.weights.h5...\n",
      "Weights saved!\n",
      "Loading expert data...\n",
      "Data loaded. Training on 875 samples...\n",
      "Epoch 1/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4193 - loss: 6.4716 - val_accuracy: 0.4773 - val_loss: 2.0909\n",
      "Epoch 2/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6798 - loss: 1.1825 - val_accuracy: 0.6705 - val_loss: 0.5021\n",
      "Epoch 3/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7154 - loss: 0.9162 - val_accuracy: 0.6250 - val_loss: 0.5141\n",
      "Epoch 4/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7179 - loss: 0.6418 - val_accuracy: 0.6705 - val_loss: 0.4814\n",
      "Epoch 5/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7446 - loss: 0.5319 - val_accuracy: 0.7727 - val_loss: 0.4718\n",
      "Epoch 6/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7510 - loss: 0.4886 - val_accuracy: 0.6136 - val_loss: 0.4967\n",
      "Epoch 7/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7878 - loss: 0.4551 - val_accuracy: 0.6023 - val_loss: 0.5781\n",
      "Epoch 8/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7675 - loss: 0.4385 - val_accuracy: 0.6477 - val_loss: 0.4667\n",
      "Epoch 9/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8043 - loss: 0.4438 - val_accuracy: 0.6364 - val_loss: 0.4823\n",
      "Epoch 10/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7903 - loss: 0.4252 - val_accuracy: 0.7500 - val_loss: 0.4658\n",
      "Epoch 11/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7789 - loss: 0.4519 - val_accuracy: 0.5909 - val_loss: 0.6314\n",
      "Epoch 12/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7560 - loss: 0.4553 - val_accuracy: 0.7386 - val_loss: 0.4542\n",
      "Epoch 13/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8056 - loss: 0.4109 - val_accuracy: 0.6023 - val_loss: 0.5531\n",
      "Epoch 14/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7980 - loss: 0.4158 - val_accuracy: 0.6250 - val_loss: 0.4923\n",
      "Epoch 15/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8043 - loss: 0.4001 - val_accuracy: 0.6023 - val_loss: 0.5091\n",
      "Epoch 16/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8069 - loss: 0.4075 - val_accuracy: 0.6136 - val_loss: 0.5393\n",
      "Epoch 17/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8069 - loss: 0.3949 - val_accuracy: 0.7386 - val_loss: 0.4792\n",
      "Epoch 18/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7675 - loss: 0.4712 - val_accuracy: 0.5909 - val_loss: 0.6210\n",
      "Epoch 19/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8272 - loss: 0.3858 - val_accuracy: 0.5909 - val_loss: 0.4966\n",
      "Epoch 20/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8247 - loss: 0.3870 - val_accuracy: 0.5909 - val_loss: 0.6328\n",
      "Epoch 21/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8221 - loss: 0.3924 - val_accuracy: 0.7045 - val_loss: 0.4742\n",
      "Epoch 22/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8196 - loss: 0.3881 - val_accuracy: 0.5909 - val_loss: 0.5517\n",
      "Epoch 23/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8208 - loss: 0.3916 - val_accuracy: 0.6023 - val_loss: 0.5723\n",
      "Epoch 24/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8018 - loss: 0.3988 - val_accuracy: 0.6932 - val_loss: 0.5391\n",
      "Epoch 25/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8170 - loss: 0.3905 - val_accuracy: 0.5682 - val_loss: 0.5567\n",
      "Training complete. Saving final weights to final_imitation.weights.h5...\n",
      "Final weights saved!\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    collect_expert_data()  #for collecting the data\n",
    "    pretrain_agent()       #for pre training\n",
    "    train_imitation_model() #for Behaveral Trainign "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406e59d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
