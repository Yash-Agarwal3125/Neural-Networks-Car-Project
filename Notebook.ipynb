{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d5d622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#required libraries\n",
    "import numpy as np\n",
    "import pygame           \n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import time\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08e17ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global constants\n",
    "\n",
    "SCREEN_WIDTH, SCREEN_HEIGHT = 1280, 720\n",
    "BG_COLOR = (120, 120, 120)\n",
    "DRAW_COLOR = (50, 50, 50)\n",
    "\n",
    "DRAW_RADIUS = 2\n",
    "ERASE_RADIUS = 5  \n",
    "\n",
    "CAR_WIDTH, CAR_HEIGHT = 20, 40\n",
    "DEFAULT_START_X, DEFAULT_START_Y = 900, 426\n",
    "DEFAULT_START_ANGLE = -45\n",
    "DEFAULT_START_SPEED = 0\n",
    "ACCELERATION = 0.05\n",
    "BRAKE_FORCE = 0.1\n",
    "MAX_SPEED = 5.00\n",
    "FRICTION = 0.025\n",
    "MIN_TURN_ANGLE = 1.5\n",
    "MAX_TURN_ANGLE = 2\n",
    "\n",
    "TRACK_SAVE_PATH = \"monza_draw.png\"\n",
    "CAR_IMAGE_PATH = \"Track_images/car.png\"\n",
    "TRACK_IMAGE_PATH = r\"Track_images\\track1.png\"\n",
    "\n",
    "finish_line_rect=pygame.Rect(DEFAULT_START_X+30,DEFAULT_START_Y-20,10,100)\n",
    "checkpoint_data=[\n",
    "    (834,520,10,120,0),\n",
    "    (600,540,10,120,0),\n",
    "    (110,569,10,120,90),\n",
    "    (285,483,10,120,0),\n",
    "    (366,314,10,120,0),\n",
    "    (355,173,10,120,0),\n",
    "    (450,109,10,120,0),\n",
    "    (606,170,10,120,0),\n",
    "    (818,91,10,120,0),\n",
    "    (1127,88,10,120,310),\n",
    "    (1094,270,10,120,0),\n",
    "    (920,346,10,120,45)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8dcd7b",
   "metadata": {},
   "source": [
    "FOR making th track drawing \n",
    "left ckick for drawing the track\n",
    "right click for eraing the track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "912d2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_track():\n",
    "    \"\"\"\n",
    "    Function to draw the racing track.\n",
    "    Left mouse button to draw, right mouse button to erase.\n",
    "    Press 'S' to save the track as an image.\n",
    "    \"\"\"\n",
    "    pygame.init()\n",
    "    pygame.display.set_caption(\"Drawing the track, press 'S' to save as image.\")\n",
    "    screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "    screen.fill(BG_COLOR)\n",
    "    running, drawing, erase = True, False, False\n",
    "    while running:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "            elif event.type == pygame.MOUSEBUTTONDOWN:\n",
    "                if event.button == 1:\n",
    "                    drawing = True\n",
    "                elif event.button == 3:\n",
    "                    erase = True\n",
    "            elif event.type == pygame.MOUSEBUTTONUP:\n",
    "                if event.button == 1:\n",
    "                    drawing = False\n",
    "                elif event.button == 3:\n",
    "                    erase = False\n",
    "            elif event.type == pygame.MOUSEMOTION:\n",
    "                mouse_pos = pygame.mouse.get_pos()\n",
    "                if drawing:\n",
    "                    pygame.draw.circle(screen, DRAW_COLOR, mouse_pos, DRAW_RADIUS)\n",
    "                elif erase:\n",
    "                    pygame.draw.circle(screen, BG_COLOR, mouse_pos, ERASE_RADIUS)\n",
    "            elif event.type == pygame.KEYDOWN and event.key == pygame.K_s:\n",
    "                pygame.image.save(screen, TRACK_SAVE_PATH)\n",
    "        pygame.display.update()\n",
    "    pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0895936",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car:\n",
    "    \"\"\"\n",
    "    Class representing a car in the racing simulation.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_path, x, y, angle=0, speed=0):\n",
    "        self.original_image = pygame.transform.scale(\n",
    "            pygame.image.load(image_path).convert_alpha(), \n",
    "            (CAR_WIDTH, CAR_HEIGHT)\n",
    "        )\n",
    "        image = pygame.image.load(image_path).convert_alpha()\n",
    "        self.image = pygame.transform.scale(image, (CAR_WIDTH, CAR_HEIGHT))\n",
    "        self.x, self.y = x, y\n",
    "        self.angle = angle\n",
    "        self.speed = speed\n",
    "        self.rect=self.image.get_rect(center=(self.x,self.y))\n",
    "        self.mask=pygame.mask.from_surface(self.image)\n",
    "\n",
    "    def move(self):\n",
    "        rad = np.radians(self.angle)\n",
    "        self.x += self.speed * np.cos(rad)\n",
    "        self.y -= self.speed * np.sin(rad)\n",
    "        self.rect.center = (self.x, self.y)\n",
    "\n",
    "    def draw(self, screen):\n",
    "        self.image = pygame.transform.rotate(self.original_image, self.angle)\n",
    "        self.rect = self.image.get_rect(center=(self.x, self.y))\n",
    "        self.mask = pygame.mask.from_surface(self.image)\n",
    "        screen.blit(self.image, self.rect.topleft)\n",
    "        \n",
    "    def get_rect(self):\n",
    "        return self.rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4346e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ray_casting(car, track_surface):\n",
    "    \"\"\"Cast rays from the car's position to detect the track boundaries.\n",
    "\n",
    "    Args:\n",
    "        car (class): The car object.\n",
    "        track_surface (Surface): The surface of the track.\n",
    "\n",
    "    Returns:\n",
    "        sensor_distance (float): The distance to the nearest track boundary.\n",
    "        sensor_endpoint (tuple): The (x, y) coordinates of the sensor endpoint.\n",
    "    \"\"\"\n",
    "    sensor_distance = []\n",
    "    sensor_endpoint = []\n",
    "    sensor_angle = [-45, 0, 45]\n",
    "\n",
    "    for angle in sensor_angle:\n",
    "        ray_angle = car.angle + angle\n",
    "        ray_x, ray_y = car.x, car.y\n",
    "        distance = 0\n",
    "        max_distance = 200\n",
    "\n",
    "        while distance < max_distance:\n",
    "            rad = np.radians(ray_angle)\n",
    "            ray_x += np.cos(rad)\n",
    "            ray_y -= np.sin(rad)\n",
    "            distance += 1\n",
    "\n",
    "            if not (0 <= ray_x < SCREEN_WIDTH and 0 <= ray_y < SCREEN_HEIGHT):\n",
    "                break\n",
    "\n",
    "            pixel_color = track_surface.get_at((int(ray_x), int(ray_y)))[0:3]\n",
    "            if pixel_color == DRAW_COLOR:\n",
    "                break\n",
    "\n",
    "        sensor_distance.append(distance)\n",
    "        sensor_endpoint.append((ray_x, ray_y))\n",
    "\n",
    "    return sensor_distance, sensor_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35516690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">739</span> (2.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m739\u001b[0m (2.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">739</span> (2.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m739\u001b[0m (2.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def model():\n",
    "    \"\"\"Builds a simple feedforward neural network model.\n",
    "\n",
    "    Returns:\n",
    "        model: A Keras Sequential model instance.\n",
    "    \"\"\"\n",
    "    model=Sequential(\n",
    "        [Dense(32,activation='relu',input_shape=(4,)),\n",
    "         Dense(16,activation='relu'),\n",
    "         Dense(3,activation='linear')]\n",
    "    )\n",
    "    model.compile(optimizer='adam',loss='mse')\n",
    "    return model\n",
    "ai_model=model()\n",
    "ai_model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f902bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"\n",
    "    A Deep Q-Network (DQN) agent for reinforcement learning.\n",
    "    Attributes:\n",
    "        model: The neural network model used for approximating Q-values.\n",
    "        memory: A deque to store past experiences for experience replay.\n",
    "        gamma: Discount factor for future rewards.\n",
    "        epsilon: Exploration rate for the epsilon-greedy policy.\n",
    "        epsilon_min: Minimum exploration rate.\n",
    "        epsilon_decay: Decay rate for exploration after each training episode.\n",
    "        batch_size: Size of the minibatch for training.\n",
    "    Methods:\n",
    "        remember: Store an experience in memory.\n",
    "        choose_action: Select an action based on the current state using an epsilon-greedy policy.\n",
    "        train_from_memory: Train the model using a minibatch of experiences from memory.\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.memory = deque(maxlen=20000) # Increased memory size for better learning\n",
    "        self.gamma = 0.95  # Discount factor: how much to value future rewards\n",
    "        self.epsilon = 1.0  # Exploration rate: initial probability of taking a random action\n",
    "        self.epsilon_min = 0.01 # Minimum exploration rate\n",
    "        self.epsilon_decay = 0.999 # Decay rate for exploration\n",
    "        self.batch_size = 32 # Increased batch size for more stable training\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Stores an experience tuple in the agent's memory.\"\"\"\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        \"\"\"\n",
    "        Selects an action based on the current state using an epsilon-greedy policy.\n",
    "        With probability epsilon, it takes a random action (exploration).\n",
    "        Otherwise, it takes the best known action (exploitation).\n",
    "        \"\"\"\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(3)  # Return a random action (0, 1, 2)\n",
    "        \n",
    "        # Predict Q-values for the given state and choose the action with the highest Q-value\n",
    "        q_values = self.model.predict(np.reshape(state, [1, 4]), verbose=0)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "    def train_from_memory(self):\n",
    "        \"\"\"Train the DQN agent using experiences from memory.\n",
    "\n",
    "        Returns:\n",
    "            float: The training loss.\n",
    "        \"\"\"\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return None # Return None if not training\n",
    "\n",
    "        minibatch = random.sample(self.memory, self.batch_size)\n",
    "        states = np.array([experience[0] for experience in minibatch])\n",
    "        actions = np.array([experience[1] for experience in minibatch])\n",
    "        rewards = np.array([experience[2] for experience in minibatch])\n",
    "        next_states = np.array([experience[3] for experience in minibatch])\n",
    "        dones = np.array([experience[4] for experience in minibatch])\n",
    "\n",
    "        current_q_values = self.model.predict(states, verbose=0)\n",
    "        next_q_values = self.model.predict(next_states, verbose=0)\n",
    "\n",
    "        targets = rewards + self.gamma * np.amax(next_q_values, axis=1) * (1 - dones)\n",
    "        \n",
    "        for i, action in enumerate(actions):\n",
    "            current_q_values[i][action] = targets[i]\n",
    "\n",
    "        # FIX: Capture the history object to get the loss\n",
    "        history = self.model.fit(states, current_q_values, epochs=1, verbose=0)\n",
    "        loss = history.history['loss'][0]\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d40d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_game_step(action, car, track_image, current_checkpoint):\n",
    "    \"\"\"\n",
    "    Simulates a game step for the car in the racing environment.\n",
    "\n",
    "    Args:\n",
    "        action (int): Action to be taken by the car (0: left, 1: straight, 2: right, 3: brake).\n",
    "        car (Car): The car object representing the player's car.\n",
    "        track_image (Surface): The image of the track.\n",
    "        current_checkpoint (int): The index of the current checkpoint.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the new state, done flag, reward, and current checkpoint.\n",
    "    \"\"\"\n",
    "    done = False\n",
    "    \n",
    "    # --- NEW MULTI-COMPONENT REWARD SYSTEM ---\n",
    "\n",
    "    # 1. Base reward: A small penalty for each step taken. \n",
    "    # This encourages the agent to finish the lap faster.\n",
    "    reward = -0.1\n",
    "\n",
    "    # 2. Reward for Speed: Encourage the car to move forward, not stand still.\n",
    "    # The reward is proportional to its speed.\n",
    "    reward += car.speed * 0.2\n",
    "\n",
    "    # 3. Reward for Progress: This is the most important part.\n",
    "    # We get the sensor readings (the state) and reward the agent\n",
    "    # for having a clear path ahead. The middle sensor (state[1]) looks forward.\n",
    "    current_state, _ = ray_casting(car, track_image)\n",
    "    # The farther the wall, the higher the reward.\n",
    "    reward += current_state[1] * 0.005 \n",
    "\n",
    "    # 4. Penalty for Sharp Turns: Discourage frantic wiggling.\n",
    "    # Encourage smoother driving by penalizing turning actions slightly.\n",
    "    if action == 0 or action == 2: # Actions for left/right turns\n",
    "        reward -= 0.2\n",
    "\n",
    "    # --- CAR PHYSICS (No changes here) ---\n",
    "    car.speed += ACCELERATION\n",
    "    if car.speed > 0:\n",
    "        speed_factor = car.speed / MAX_SPEED\n",
    "        dynamic_turn_angle = MAX_TURN_ANGLE - (speed_factor) * (MAX_TURN_ANGLE - MIN_TURN_ANGLE)\n",
    "        if action == 0:  # Left\n",
    "            car.angle += dynamic_turn_angle\n",
    "        elif action == 1:  # Right\n",
    "            car.angle -= dynamic_turn_angle\n",
    "    \n",
    "    if action == 2: # Brake\n",
    "        car.speed -= BRAKE_FORCE\n",
    "    \n",
    "    car.speed -= FRICTION\n",
    "    car.speed = max(0, min(car.speed, MAX_SPEED))\n",
    "    car.move()\n",
    "    \n",
    "    # --- GOAL-BASED REWARDS (Checkpoints and Crashing) ---\n",
    "    checkpoint_rects = [pygame.Rect(x, y, w, h) for x, y, w, h, a in checkpoint_data]\n",
    "    \n",
    "    # 5. Large reward for hitting a checkpoint.\n",
    "    if current_checkpoint < len(checkpoint_rects):\n",
    "        if car.rect.colliderect(checkpoint_rects[current_checkpoint]):\n",
    "            current_checkpoint += 1\n",
    "            reward += 30 # Large positive reward\n",
    "            print(f\"Checkpoint {current_checkpoint} reached!\")\n",
    "\n",
    "    # 6. Very large reward for finishing the lap.\n",
    "    if current_checkpoint == len(checkpoint_rects) and car.rect.colliderect(finish_line_rect):\n",
    "        reward += 300\n",
    "        current_checkpoint = 0\n",
    "        print(\"Lap finished!\")\n",
    "\n",
    "    # 7. Large penalty for crashing.\n",
    "    try:\n",
    "        pixel_color = track_image.get_at((int(car.x), int(car.y)))[:3]\n",
    "        if pixel_color == DRAW_COLOR:\n",
    "            done = True\n",
    "    except IndexError:\n",
    "        done = True\n",
    "        \n",
    "    if done:\n",
    "        reward = -20 # Keep a significant penalty for crashing, but not as extreme as -100\n",
    "\n",
    "    new_state, _ = ray_casting(car, track_image)\n",
    "    return new_state, done, reward, current_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbe761f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn(episodes=500):\n",
    "    \"\"\"\n",
    "    Main function to train the DQN agent with enhanced logging.\n",
    "    \"\"\"\n",
    "    pygame.init()\n",
    "    screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "    track_surface = pygame.image.load(TRACK_IMAGE_PATH).convert()\n",
    "    \n",
    "    ai_model = model()\n",
    "    agent = DQNAgent(ai_model)\n",
    "\n",
    "    scores_history = []\n",
    "    loss_history = []\n",
    "    \n",
    "    for e in range(episodes):\n",
    "        car = Car(CAR_IMAGE_PATH, DEFAULT_START_X, DEFAULT_START_Y, DEFAULT_START_ANGLE, DEFAULT_START_SPEED)\n",
    "        current_checkpoint = 0\n",
    "        \n",
    "        distances, _ = ray_casting(car, track_surface)\n",
    "        speed = car.speed / MAX_SPEED \n",
    "        state = np.array(distances + [speed]) \n",
    "        state = np.reshape(state, [1, 4])\n",
    "        \n",
    "        total_reward = 0\n",
    "        max_steps_per_episode = 2000\n",
    "        \n",
    "        # NEW: Initialize trackers for the episode\n",
    "        max_speed_episode = 0\n",
    "\n",
    "        for step in range(max_steps_per_episode):\n",
    "            action = agent.choose_action(state)\n",
    "            distances_next, done, reward, new_checkpoint = model_game_step(action, car, track_surface, current_checkpoint)\n",
    "            \n",
    "            # NEW: Update max speed for the episode after the car moves\n",
    "            max_speed_episode = max(max_speed_episode, car.speed)\n",
    "            \n",
    "            total_reward += reward\n",
    "            speed_next = car.speed / MAX_SPEED \n",
    "            next_state = np.array(distances_next + [speed_next])\n",
    "            next_state = np.reshape(next_state, [1, 4])\n",
    "            current_checkpoint = new_checkpoint\n",
    "            \n",
    "            agent.remember(state[0], action, reward, next_state[0], done)\n",
    "            state = next_state\n",
    "            \n",
    "            loss = agent.train_from_memory()\n",
    "            if loss is not None:\n",
    "                loss_history.append(loss)\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        scores_history.append(total_reward)\n",
    "        \n",
    "        # MODIFIED: Updated print statement with more data\n",
    "        print(\n",
    "            f\"Episode: {e+1}/{episodes}, \"\n",
    "            f\"Score: {total_reward:.2f}, \"\n",
    "            f\"Max Speed: {max_speed_episode:.2f}, \"\n",
    "            f\"Checkpoints: {current_checkpoint}, \"\n",
    "            f\"Epsilon: {agent.epsilon:.2f}\"\n",
    "        )\n",
    "\n",
    "        if (e + 1) % 50 == 0:\n",
    "            ai_model.save_weights(f\"dqn_car_weights_episode_{e+1}.weights.h5\")\n",
    "\n",
    "    pygame.quit()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "    # Plot Score vs. Episode\n",
    "    ax1.plot(scores_history, label='Score per Episode', color='royalblue')\n",
    "    ax1.set_title('Agent Score Over Time')\n",
    "    ax1.set_xlabel('Episode')\n",
    "    ax1.set_ylabel('Total Reward')\n",
    "    ax1.legend()\n",
    "\n",
    "    # Plot Loss vs. Training Step\n",
    "    ax2.plot(loss_history, label='Training Loss', color='orangered', alpha=0.7)\n",
    "    ax2.set_title('Model Loss Over Time')\n",
    "    ax2.set_xlabel('Training Step')\n",
    "    ax2.set_ylabel('MSE Loss')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af0f3dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ai_simulation():\n",
    "    \"\"\"Runs the car simulation controlled by an AI model.\n",
    "        The AI model predicts actions based on the car's sensor data.\n",
    "        0: turn left\n",
    "        1: accelerate\n",
    "        2: turn right\n",
    "        3: brake\n",
    "    \"\"\"\n",
    "    pygame.init()\n",
    "    screen=pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "    clock=pygame.time.Clock()\n",
    "    pygame.display.set_caption(\"AI Car Simulation\")\n",
    "    track_surface=pygame.image.load(TRACK_IMAGE_PATH).convert()\n",
    "    car=Car(CAR_IMAGE_PATH,DEFAULT_START_X,DEFAULT_START_Y,DEFAULT_START_ANGLE,DEFAULT_START_SPEED)\n",
    "    font=pygame.font.SysFont(None,22)\n",
    "    \n",
    "    running=True\n",
    "    while running:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type==pygame.QUIT:\n",
    "                running=False\n",
    "        current_state,ray_endpoints=ray_casting(car,track_surface)\n",
    "        reshaped_state = np.reshape(current_state, [1, 3])\n",
    "        q_values = ai_model.predict(reshaped_state, verbose=0)\n",
    "        action = np.argmax(q_values[0])\n",
    "        _ ,_ ,done=model_game_step(action,car,track_surface)\n",
    "        if done:\n",
    "            text_surface = font.render(\"Car Crashed! Resetting...\", True, (255, 255, 255))\n",
    "            screen.blit(text_surface, (50, 50))\n",
    "            pygame.display.update()\n",
    "            pygame.time.wait(1000)\n",
    "            car=Car(CAR_IMAGE_PATH,DEFAULT_START_X,DEFAULT_START_Y,DEFAULT_START_ANGLE,DEFAULT_START_SPEED)\n",
    "        \n",
    "        screen.blit(track_surface,(0,0))\n",
    "        car.draw(screen)\n",
    "        \n",
    "        text_surface = font.render(f\"Distances: {current_state}\", True, (255, 255, 255))\n",
    "        screen.blit(text_surface, (50, 80))\n",
    "        for points in ray_endpoints:\n",
    "            pygame.draw.line(screen,(0,255,0),(car.x,car.y),points,1)\n",
    "            \n",
    "        pygame.display.update()\n",
    "        clock.tick(60)\n",
    "    pygame.quit()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e04541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(\n",
    "    start_x=DEFAULT_START_X,\n",
    "    start_y=DEFAULT_START_Y,\n",
    "    start_angle=DEFAULT_START_ANGLE,\n",
    "    start_speed=DEFAULT_START_SPEED\n",
    "):\n",
    "    \"\"\"Runs the car simulation manually by the user.\n",
    "\n",
    "    Args:\n",
    "        start_x (int, optional): The starting x-coordinate of the car. Defaults to DEFAULT_START_X.\n",
    "        start_y (int, optional): The starting y-coordinate of the car. Defaults to DEFAULT_START_Y.\n",
    "        start_angle (float, optional): The starting angle of the car. Defaults to DEFAULT_START_ANGLE.\n",
    "        start_speed (float, optional): The starting speed of the car. Defaults to DEFAULT_START_SPEED.\n",
    "    \"\"\"\n",
    "    pygame.init()\n",
    "    screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "    clock = pygame.time.Clock()\n",
    "    pygame.display.set_caption(\"Car Simulation\")\n",
    "\n",
    "    track_image = pygame.image.load(TRACK_IMAGE_PATH).convert()\n",
    "    track_surface = track_image.copy()\n",
    "\n",
    "    car = Car(CAR_IMAGE_PATH, start_x, start_y, start_angle, start_speed)\n",
    "\n",
    "    screen.fill(BG_COLOR)\n",
    "    screen.blit(track_image, (0, 0))\n",
    "\n",
    "    CAR_ROAD_COLOR = track_surface.get_at((start_x, start_y))[:3]\n",
    "\n",
    "  \n",
    "\n",
    "    lap_start_time=0\n",
    "    best_lap_time=float('inf')\n",
    "    current_lap_time=0\n",
    "    lap_started=False\n",
    "    car_on_finish=False\n",
    "\n",
    "    car_max_speed = 0\n",
    "    \n",
    "    #checkpoints\n",
    "    checkpoints=[]\n",
    "    \n",
    "    for x,y,w,h,a in checkpoint_data:\n",
    "        base_surface=pygame.Surface((w,h),pygame.SRCALPHA)\n",
    "        base_surface.fill((255,0,255,100))\n",
    "        rotated_surface=pygame.transform.rotate(base_surface,a)\n",
    "        rect=rotated_surface.get_rect(center=(x,y))\n",
    "        mask=pygame.mask.from_surface(rotated_surface)\n",
    "        checkpoints.append({'surface': rotated_surface, 'rect': rect, 'mask': mask})\n",
    "    current_checkpoint=0\n",
    "\n",
    "    running = True\n",
    "    while running:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "        keys = pygame.key.get_pressed()\n",
    "        if car.speed > 0:\n",
    "            car.speed -= FRICTION\n",
    "        if car.speed < 0:\n",
    "            car.speed += FRICTION\n",
    "        if abs(car.speed) < FRICTION:\n",
    "            car.speed = 0\n",
    "        if keys[pygame.K_DOWN]:\n",
    "            car.speed -= BRAKE_FORCE\n",
    "        if keys[pygame.K_UP]:\n",
    "            if car.speed < MAX_SPEED:\n",
    "                car.speed += ACCELERATION\n",
    "                \n",
    "        if car.speed > 0.1:\n",
    "            speed_factor = car.speed / MAX_SPEED\n",
    "            turn_range = MAX_TURN_ANGLE - MIN_TURN_ANGLE\n",
    "            dynamic_turn_angle = MAX_TURN_ANGLE - (speed_factor * turn_range)\n",
    "        \n",
    "            if keys[pygame.K_LEFT]:\n",
    "                car.angle += dynamic_turn_angle\n",
    "            if keys[pygame.K_RIGHT]:\n",
    "                car.angle -= dynamic_turn_angle\n",
    "\n",
    "        screen.blit(track_image, (0, 0))\n",
    "\n",
    "        font = pygame.font.Font(None, 22)\n",
    "        text_surface = font.render(f\"Speed: {car.speed:.2f}\", True, (255, 255, 255))\n",
    "        screen.blit(text_surface, (50, 50))\n",
    "\n",
    "        # Ray casting\n",
    "        distance, sensor_endpoint = ray_casting(car, track_surface)\n",
    "        text_surface = font.render(f\"Distances: {distance}\", True, (255, 255, 255))\n",
    "        screen.blit(text_surface, (50, 80))\n",
    "        for endpoint in sensor_endpoint:\n",
    "            pygame.draw.line(screen, (0, 255, 0), (car.x, car.y), endpoint, 1)\n",
    "\n",
    "        car.move()\n",
    "        \n",
    "        #cheking checkpoints\n",
    "        if current_checkpoint < len(checkpoints):\n",
    "            target = checkpoints[current_checkpoint]\n",
    "\n",
    "            # compute offset of target mask relative to car mask\n",
    "            offset_x = target['rect'].left - car.rect.left\n",
    "            offset_y = target['rect'].top  - car.rect.top\n",
    "\n",
    "\n",
    "            if (offset_y==0 and -60<offset_x<60) or (offset_x==0 and -60<offset_y<60):\n",
    "                current_checkpoint += 1\n",
    "                print(f\"Checkpoint reached! {current_checkpoint}\")\n",
    "\n",
    "        \n",
    "        car.draw(screen)\n",
    "        \n",
    "        for i, cp in enumerate(checkpoints):\n",
    "          screen.blit(cp['surface'], cp['rect'])\n",
    "          if i == current_checkpoint:\n",
    "              pygame.draw.rect(screen, (0, 255, 0), cp['rect'], 3)\n",
    "        \n",
    "        #lap timing (collision detection)\n",
    "        is_colliding=car.get_rect().colliderect(finish_line_rect)\n",
    "        if is_colliding and not car_on_finish:\n",
    "            car_on_finish=True\n",
    "            if lap_started and current_checkpoint == len(checkpoints):\n",
    "                lap_time=time.time()-lap_start_time\n",
    "                best_lap_time=min(best_lap_time,lap_time)\n",
    "                lap_start_time=time.time()\n",
    "                current_checkpoint=0\n",
    "            elif not lap_started:\n",
    "                lap_started = True\n",
    "                lap_start_time = time.time()\n",
    "                current_checkpoint = 0\n",
    "        if not is_colliding:\n",
    "            car_on_finish=False\n",
    "            \n",
    "        pygame.draw.rect(screen, (250, 100, 50), finish_line_rect)\n",
    "        \n",
    "\n",
    "        # Collision detection (including out-of-bounds)\n",
    "        crashed = False\n",
    "        car_center_pos = (int(car.x), int(car.y))\n",
    "        if not (0 <= car.x < SCREEN_WIDTH and 0 <= car.y < SCREEN_HEIGHT):\n",
    "            crashed = True\n",
    "        else:\n",
    "            try:\n",
    "                pixel_color = track_surface.get_at(car_center_pos)[:3]\n",
    "                if pixel_color != CAR_ROAD_COLOR:\n",
    "                    crashed = True\n",
    "            except IndexError:\n",
    "                crashed = True\n",
    "\n",
    "        if crashed:\n",
    "            lap_started=False\n",
    "            current_lap_time=0 \n",
    "            current_checkpoint=0\n",
    "            text_surface = font.render(\"Car has crashed!\", True, (255, 255, 255))\n",
    "            screen.blit(text_surface, (50, 110))\n",
    "            pygame.display.update()\n",
    "            pygame.time.wait(1000)  # Show message for 1 second\n",
    "            car.x, car.y = start_x, start_y\n",
    "            car.angle = start_angle\n",
    "            car.speed = start_speed\n",
    "\n",
    "        if car.speed > car_max_speed:\n",
    "            car_max_speed = car.speed\n",
    "\n",
    "        if lap_started:\n",
    "            current_lap_time = time.time() - lap_start_time\n",
    "            current_lap_str = f\"Lap: {current_lap_time:.2f}s\"\n",
    "        else:\n",
    "            current_lap_str = \"Lap: 0.00s\"                                           \n",
    "        best_lap_str = f\"Best: {best_lap_time:.2f}s\" if best_lap_time != float('inf') else \"Best: N/A\"\n",
    "        text_surface = font.render(current_lap_str, True, (255, 255, 255))            \n",
    "        screen.blit(text_surface, (50, 500))\n",
    "        best_text = font.render(best_lap_str, True, (255, 255, 255))\n",
    "        screen.blit(best_text, (50, 530))\n",
    "        text_surface = font.render(f\"Max speed: {car_max_speed:.2f}\", True, (255, 255, 255))\n",
    "        screen.blit(text_surface, (50, 470))\n",
    "\n",
    "        pygame.display.update()\n",
    "        clock.tick(60)\n",
    "\n",
    "    pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07ea071",
   "metadata": {},
   "source": [
    "        if event.type == pygame.MOUSEMOTION:\n",
    "            mouse_point = event.pos\n",
    "            text_surface = font.render(f\"Location: {mouse_point}\", True, (255, 255, 255))\n",
    "            screen.blit(text_surface, (50, 100))\n",
    " #code for getting mouse location\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "823c5ef8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m#draw_track()\u001b[39;00m\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m#run_simulation()\u001b[39;00m\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# run_ai_simulation()\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43mtrain_dqn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisodes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mtrain_dqn\u001b[39m\u001b[34m(episodes)\u001b[39m\n\u001b[32m     43\u001b[39m agent.remember(state[\u001b[32m0\u001b[39m], action, reward, next_state[\u001b[32m0\u001b[39m], done)\n\u001b[32m     44\u001b[39m state = next_state\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m loss = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_from_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     48\u001b[39m     loss_history.append(loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mDQNAgent.train_from_memory\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     57\u001b[39m dones = np.array([experience[\u001b[32m4\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m experience \u001b[38;5;129;01min\u001b[39;00m minibatch])\n\u001b[32m     59\u001b[39m current_q_values = \u001b[38;5;28mself\u001b[39m.model.predict(states, verbose=\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m next_q_values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m targets = rewards + \u001b[38;5;28mself\u001b[39m.gamma * np.amax(next_q_values, axis=\u001b[32m1\u001b[39m) * (\u001b[32m1\u001b[39m - dones)\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(actions):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:505\u001b[39m, in \u001b[36mTensorFlowTrainer.predict\u001b[39m\u001b[34m(self, x, batch_size, verbose, steps, callbacks)\u001b[39m\n\u001b[32m    500\u001b[39m \u001b[38;5;129m@traceback_utils\u001b[39m.filter_traceback\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\n\u001b[32m    502\u001b[39m     \u001b[38;5;28mself\u001b[39m, x, batch_size=\u001b[38;5;28;01mNone\u001b[39;00m, verbose=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m, steps=\u001b[38;5;28;01mNone\u001b[39;00m, callbacks=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    503\u001b[39m ):\n\u001b[32m    504\u001b[39m     \u001b[38;5;66;03m# Create an iterator that yields batches of input data.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     epoch_iterator = \u001b[43mTFEpochIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    514\u001b[39m     \u001b[38;5;66;03m# Container that configures and calls callbacks.\u001b[39;00m\n\u001b[32m    515\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module.CallbackList):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:728\u001b[39m, in \u001b[36mTFEpochIterator.__init__\u001b[39m\u001b[34m(self, distribute_strategy, *args, **kwargs)\u001b[39m\n\u001b[32m    726\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(*args, **kwargs)\n\u001b[32m    727\u001b[39m \u001b[38;5;28mself\u001b[39m._distribute_strategy = distribute_strategy\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m dataset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_adapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tf_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, tf.distribute.DistributedDataset):\n\u001b[32m    730\u001b[39m     dataset = \u001b[38;5;28mself\u001b[39m._distribute_strategy.experimental_distribute_dataset(\n\u001b[32m    731\u001b[39m         dataset\n\u001b[32m    732\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\array_data_adapter.py:235\u001b[39m, in \u001b[36mArrayDataAdapter.get_tf_dataset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle == \u001b[33m\"\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    233\u001b[39m     indices_dataset = indices_dataset.map(tf.random.shuffle)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m dataset = \u001b[43mslice_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    237\u001b[39m options = tf.data.Options()\n\u001b[32m    238\u001b[39m options.experimental_distribute.auto_shard_policy = (\n\u001b[32m    239\u001b[39m     tf.data.experimental.AutoShardPolicy.DATA\n\u001b[32m    240\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\array_data_adapter.py:214\u001b[39m, in \u001b[36mArrayDataAdapter.get_tf_dataset.<locals>.slice_inputs\u001b[39m\u001b[34m(indices_dataset, inputs)\u001b[39m\n\u001b[32m    210\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tree.traverse(grab_one, data)\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m dataset = \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrab_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAUTOTUNE\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[38;5;66;03m# Default optimizations are disabled to avoid the overhead of\u001b[39;00m\n\u001b[32m    219\u001b[39m \u001b[38;5;66;03m# (unnecessary) input pipeline graph serialization & deserialization\u001b[39;00m\n\u001b[32m    220\u001b[39m options = tf.data.Options()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2341\u001b[39m, in \u001b[36mDatasetV2.map\u001b[39m\u001b[34m(self, map_func, num_parallel_calls, deterministic, synchronous, use_unbounded_threadpool, name)\u001b[39m\n\u001b[32m   2336\u001b[39m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[32m   2337\u001b[39m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[32m   2338\u001b[39m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[32m   2339\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[32m-> \u001b[39m\u001b[32m2341\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2342\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2343\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2344\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2345\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2346\u001b[39m \u001b[43m    \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2347\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_unbounded_threadpool\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_unbounded_threadpool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2349\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:57\u001b[39m, in \u001b[36m_map_v2\u001b[39m\u001b[34m(input_dataset, map_func, num_parallel_calls, deterministic, synchronous, use_unbounded_threadpool, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m synchronous:\n\u001b[32m     52\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     53\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33m`synchronous` is not supported with `num_parallel_calls`, but\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     54\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33m `num_parallel_calls` was set to \u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     55\u001b[39m       num_parallel_calls,\n\u001b[32m     56\u001b[39m   )\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ParallelMapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_unbounded_threadpool\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_unbounded_threadpool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:202\u001b[39m, in \u001b[36m_ParallelMapDataset.__init__\u001b[39m\u001b[34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, use_unbounded_threadpool, name)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28mself\u001b[39m._input_dataset = input_dataset\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m._use_inter_op_parallelism = use_inter_op_parallelism\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m \u001b[38;5;28mself\u001b[39m._map_func = \u001b[43mstructured_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    208\u001b[39m   \u001b[38;5;28mself\u001b[39m._deterministic = \u001b[33m\"\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:265\u001b[39m, in \u001b[36mStructuredFunctionWrapper.__init__\u001b[39m\u001b[34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[39m\n\u001b[32m    258\u001b[39m       warnings.warn(\n\u001b[32m    259\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    260\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    261\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    262\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    263\u001b[39m     fn_factory = trace_tf_function(defun_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m \u001b[38;5;28mself\u001b[39m._function = \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[32m    267\u001b[39m add_to_graph &= \u001b[38;5;129;01mnot\u001b[39;00m context.executing_eagerly()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1256\u001b[39m, in \u001b[36mFunction.get_concrete_function\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1254\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m   1255\u001b[39m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1256\u001b[39m   concrete = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1257\u001b[39m   concrete._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m   1258\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1226\u001b[39m, in \u001b[36mFunction._get_concrete_function_garbage_collected\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1224\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     initializers = []\n\u001b[32m-> \u001b[39m\u001b[32m1226\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1227\u001b[39m     \u001b[38;5;28mself\u001b[39m._initialize_uninitialized_variables(initializers)\n\u001b[32m   1229\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m   1230\u001b[39m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[32m   1231\u001b[39m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:696\u001b[39m, in \u001b[36mFunction._initialize\u001b[39m\u001b[34m(self, args, kwds, add_initializers_to)\u001b[39m\n\u001b[32m    691\u001b[39m \u001b[38;5;28mself\u001b[39m._variable_creation_config = \u001b[38;5;28mself\u001b[39m._generate_scoped_tracing_options(\n\u001b[32m    692\u001b[39m     variable_capturing_scope,\n\u001b[32m    693\u001b[39m     tracing_compilation.ScopeType.VARIABLE_CREATION,\n\u001b[32m    694\u001b[39m )\n\u001b[32m    695\u001b[39m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m696\u001b[39m \u001b[38;5;28mself\u001b[39m._concrete_variable_creation_fn = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvalid_creator_scope\u001b[39m(*unused_args, **unused_kwds):\n\u001b[32m    701\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[39m, in \u001b[36mtrace_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    175\u001b[39m     args = tracing_options.input_signature\n\u001b[32m    176\u001b[39m     kwargs = {}\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m   concrete_function = \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options.bind_graph_to_function:\n\u001b[32m    183\u001b[39m   concrete_function._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001b[39m, in \u001b[36m_maybe_define_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    282\u001b[39m   target_func_type = lookup_func_type\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m concrete_function = \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tracing_options.function_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    288\u001b[39m   tracing_options.function_cache.add(\n\u001b[32m    289\u001b[39m       concrete_function, current_func_context\n\u001b[32m    290\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:310\u001b[39m, in \u001b[36m_create_concrete_function\u001b[39m\u001b[34m(function_type, type_context, func_graph, tracing_options)\u001b[39m\n\u001b[32m    303\u001b[39m   placeholder_bound_args = function_type.placeholder_arguments(\n\u001b[32m    304\u001b[39m       placeholder_context\n\u001b[32m    305\u001b[39m   )\n\u001b[32m    307\u001b[39m disable_acd = tracing_options.attributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options.attributes.get(\n\u001b[32m    308\u001b[39m     attributes_lib.DISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    309\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m traced_func_graph = \u001b[43mfunc_graph_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction_type_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m transform.apply_func_graph_transforms(traced_func_graph)\n\u001b[32m    324\u001b[39m graph_capture_container = traced_func_graph.function_captures\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1065\u001b[39m, in \u001b[36mfunc_graph_from_py_func\u001b[39m\u001b[34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[39m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[32m   1064\u001b[39m func_outputs = variable_utils.convert_variables_to_tensors(func_outputs)\n\u001b[32m-> \u001b[39m\u001b[32m1065\u001b[39m func_outputs = \u001b[43mnest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1066\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1068\u001b[39m \u001b[38;5;66;03m# flatten and unflatten func_args and func_kwargs to maintain parity\u001b[39;00m\n\u001b[32m   1069\u001b[39m \u001b[38;5;66;03m# from flattening which sorts by key\u001b[39;00m\n\u001b[32m   1070\u001b[39m func_args = nest.pack_sequence_as(\n\u001b[32m   1071\u001b[39m     func_args,\n\u001b[32m   1072\u001b[39m     nest.flatten(func_args, expand_composites=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m   1073\u001b[39m     expand_composites=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\nest.py:628\u001b[39m, in \u001b[36mmap_structure\u001b[39m\u001b[34m(func, *structure, **kwargs)\u001b[39m\n\u001b[32m    542\u001b[39m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mnest.map_structure\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    543\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap_structure\u001b[39m(func, *structure, **kwargs):\n\u001b[32m    544\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[32m    545\u001b[39m \n\u001b[32m    546\u001b[39m \u001b[33;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    626\u001b[39m \u001b[33;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[32m    627\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m628\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[43m.\u001b[49m\u001b[43mModality\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\nest_util.py:1065\u001b[39m, in \u001b[36mmap_structure\u001b[39m\u001b[34m(modality, func, *structure, **kwargs)\u001b[39m\n\u001b[32m    968\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[32m    969\u001b[39m \n\u001b[32m    970\u001b[39m \u001b[33;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1062\u001b[39m \u001b[33;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m modality == Modality.CORE:\n\u001b[32m-> \u001b[39m\u001b[32m1065\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1066\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m modality == Modality.DATA:\n\u001b[32m   1067\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, *structure, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\nest_util.py:1105\u001b[39m, in \u001b[36m_tf_core_map_structure\u001b[39m\u001b[34m(func, *structure, **kwargs)\u001b[39m\n\u001b[32m   1100\u001b[39m flat_structure = (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[32m   1101\u001b[39m entries = \u001b[38;5;28mzip\u001b[39m(*flat_structure)\n\u001b[32m   1103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[32m   1104\u001b[39m     structure[\u001b[32m0\u001b[39m],\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[32m   1106\u001b[39m     expand_composites=expand_composites,\n\u001b[32m   1107\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1056\u001b[39m, in \u001b[36mfunc_graph_from_py_func.<locals>.convert\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   1050\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo be compatible with tf.function, Python functions \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1051\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmust return zero or more Tensors or ExtensionTypes or None \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1052\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvalues; in compilation of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(python_func)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, found return \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1053\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvalue of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, which is not a Tensor or \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1054\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mExtensionType.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m add_control_dependencies:\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m   x = \u001b[43mdeps_ctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmark_as_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps.py:246\u001b[39m, in \u001b[36mAutomaticControlDependencies.mark_as_return\u001b[39m\u001b[34m(self, tensor)\u001b[39m\n\u001b[32m    241\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m tensor_array_ops.build_ta_with_new_flow(tensor, flow)\n\u001b[32m    242\u001b[39m \u001b[38;5;66;03m# We want to make the return values depend on the stateful operations, but\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[38;5;66;03m# we don't want to introduce a cycle, so we make the return value the result\u001b[39;00m\n\u001b[32m    244\u001b[39m \u001b[38;5;66;03m# of a new identity operation that the stateful operations definitely don't\u001b[39;00m\n\u001b[32m    245\u001b[39m \u001b[38;5;66;03m# depend on.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m tensor = \u001b[43marray_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43midentity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[38;5;28mself\u001b[39m._returned_tensors.add(tensor)\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:88\u001b[39m, in \u001b[36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     87\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m   bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m     90\u001b[39m   bound_arguments.apply_defaults()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1264\u001b[39m, in \u001b[36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1262\u001b[39m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1265\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m   1266\u001b[39m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1267\u001b[39m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1268\u001b[39m   result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:310\u001b[39m, in \u001b[36midentity\u001b[39m\u001b[34m(input, name)\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m context.executing_eagerly() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28minput\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgraph\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    307\u001b[39m   \u001b[38;5;66;03m# Make sure we get an input with handle data attached from the resource\u001b[39;00m\n\u001b[32m    308\u001b[39m   \u001b[38;5;66;03m# variables. Variables have correct handle data when graph building.\u001b[39;00m\n\u001b[32m    309\u001b[39m   \u001b[38;5;28minput\u001b[39m = ops.convert_to_tensor(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m ret = \u001b[43mgen_array_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43midentity\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;66;03m# Propagate handles data for happier shape inference for resource variables.\u001b[39;00m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28minput\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_handle_data\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:4239\u001b[39m, in \u001b[36midentity\u001b[39m\u001b[34m(input, name)\u001b[39m\n\u001b[32m   4237\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[32m   4238\u001b[39m \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4239\u001b[39m _, _, _op, _outputs = \u001b[43m_op_def_library\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4240\u001b[39m \u001b[43m      \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mIdentity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4241\u001b[39m _result = _outputs[:]\n\u001b[32m   4242\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _execute.must_record_gradient():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:796\u001b[39m, in \u001b[36m_apply_op_helper\u001b[39m\u001b[34m(op_type_name, name, **keywords)\u001b[39m\n\u001b[32m    791\u001b[39m must_colocate_inputs = [val \u001b[38;5;28;01mfor\u001b[39;00m arg, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(op_def.input_arg, inputs)\n\u001b[32m    792\u001b[39m                         \u001b[38;5;28;01mif\u001b[39;00m arg.is_ref]\n\u001b[32m    793\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[32m    794\u001b[39m   \u001b[38;5;66;03m# Add Op to graph\u001b[39;00m\n\u001b[32m    795\u001b[39m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m796\u001b[39m   op = \u001b[43mg\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattr_protos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m=\u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[38;5;66;03m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[32m    801\u001b[39m \u001b[38;5;66;03m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[32m    803\u001b[39m \u001b[38;5;66;03m# for more details.\u001b[39;00m\n\u001b[32m    804\u001b[39m outputs = op.outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:614\u001b[39m, in \u001b[36mFuncGraph._create_op_internal\u001b[39m\u001b[34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[39m\n\u001b[32m    612\u001b[39m   inp = \u001b[38;5;28mself\u001b[39m.capture(inp)\n\u001b[32m    613\u001b[39m   captured_inputs.append(inp)\n\u001b[32m--> \u001b[39m\u001b[32m614\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    615\u001b[39m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2726\u001b[39m, in \u001b[36mGraph._create_op_internal\u001b[39m\u001b[34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[39m\n\u001b[32m   2723\u001b[39m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[32m   2724\u001b[39m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[32m   2725\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mutation_lock():\n\u001b[32m-> \u001b[39m\u001b[32m2726\u001b[39m   ret = \u001b[43mOperation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_node_def\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2727\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2728\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2729\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2730\u001b[39m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2731\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2732\u001b[39m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2733\u001b[39m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2734\u001b[39m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m=\u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2735\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2736\u001b[39m   \u001b[38;5;28mself\u001b[39m._create_op_helper(ret, compute_device=compute_device)\n\u001b[32m   2737\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1221\u001b[39m, in \u001b[36mOperation.from_node_def\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   1218\u001b[39m     control_input_ops.append(control_op)\n\u001b[32m   1220\u001b[39m \u001b[38;5;66;03m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m c_op = \u001b[43m_create_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_input_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m=\u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[38;5;28mself\u001b[39m = Operation(c_op, SymbolicTensor)\n\u001b[32m   1223\u001b[39m \u001b[38;5;28mself\u001b[39m._init(g)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1051\u001b[39m, in \u001b[36m_create_c_op\u001b[39m\u001b[34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[39m\n\u001b[32m   1049\u001b[39m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m   1050\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m graph._c_graph.get() \u001b[38;5;28;01mas\u001b[39;00m c_graph:\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m   op_desc = \u001b[43mpywrap_tf_session\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTF_NewOperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m                                              \u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m.\u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m                                              \u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m node_def.device:\n\u001b[32m   1055\u001b[39m   pywrap_tf_session.TF_SetDevice(op_desc, compat.as_str(node_def.device))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #draw_track()\n",
    "    #run_simulation()\n",
    "    # run_ai_simulation()\n",
    "    train_dqn(episodes=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3a12d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RUNNING VISUAL SANITY CHECK ---\n",
      "Initial Car Position: (900.00, 426.00)\n",
      "Is the car on the track? Look at the screen.\n",
      "\n",
      "Taking ONE random action: Brake\n",
      "Position after one move: (900.00, 426.00)\n",
      "Did it crash? (done = False)\n",
      "\n",
      ">>> TEST PASSED: The car survived its first move.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"--- RUNNING VISUAL SANITY CHECK ---\")\n",
    "    \n",
    "    # 1. Setup the environment\n",
    "    pygame.init()\n",
    "    screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "    track_surface = pygame.image.load(TRACK_IMAGE_PATH).convert()\n",
    "    \n",
    "    # 2. Place the car at its starting position\n",
    "    car = Car(CAR_IMAGE_PATH, DEFAULT_START_X, DEFAULT_START_Y, DEFAULT_START_ANGLE, DEFAULT_START_SPEED)\n",
    "\n",
    "    # 3. Draw the initial state\n",
    "    screen.blit(track_surface, (0, 0))\n",
    "    car.draw(screen)\n",
    "    pygame.display.update()\n",
    "    \n",
    "    print(f\"Initial Car Position: ({car.x:.2f}, {car.y:.2f})\")\n",
    "    print(\"Is the car on the track? Look at the screen.\")\n",
    "    time.sleep(5) # PAUSE FOR 5 SECONDS TO LET YOU SEE\n",
    "\n",
    "    # 4. Take ONE random action\n",
    "    action = random.randrange(3)\n",
    "    print(f\"\\nTaking ONE random action: {['Left', 'Right', 'Brake'][action]}\")\n",
    "    _, done, _, _ = model_game_step(action, car, track_surface, 0)\n",
    "\n",
    "    # 5. Draw the state AFTER one move\n",
    "    screen.blit(track_surface, (0, 0))\n",
    "    car.draw(screen)\n",
    "    pygame.display.update()\n",
    "\n",
    "    print(f\"Position after one move: ({car.x:.2f}, {car.y:.2f})\")\n",
    "    print(f\"Did it crash? (done = {done})\")\n",
    "    if done:\n",
    "        print(\"\\n>>> TEST FAILED: The car crashed on its very first move!\")\n",
    "    else:\n",
    "        print(\"\\n>>> TEST PASSED: The car survived its first move.\")\n",
    "\n",
    "    time.sleep(5) # PAUSE AGAIN\n",
    "    pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a339f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2b6a61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
