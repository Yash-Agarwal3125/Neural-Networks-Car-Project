{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d5d622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os         \n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"    # To run pygame without a display (for headless environments)\n",
    "\n",
    "#required libraries\n",
    "import numpy as np\n",
    "import pygame           \n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import time\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08e17ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global constants\n",
    "\n",
    "SCREEN_WIDTH, SCREEN_HEIGHT = 1280, 720\n",
    "BG_COLOR = (120, 120, 120)\n",
    "DRAW_COLOR = (50, 50, 50)\n",
    "\n",
    "DRAW_RADIUS = 2\n",
    "ERASE_RADIUS = 5  \n",
    "\n",
    "CAR_WIDTH, CAR_HEIGHT = 20, 40\n",
    "DEFAULT_START_X, DEFAULT_START_Y = 900, 426\n",
    "DEFAULT_START_ANGLE = -45\n",
    "DEFAULT_START_SPEED = 0\n",
    "ACCELERATION = 0.05\n",
    "BRAKE_FORCE = 0.1\n",
    "MAX_SPEED = 5.00\n",
    "FRICTION = 0.025\n",
    "MIN_TURN_ANGLE = 1.5\n",
    "MAX_TURN_ANGLE = 2\n",
    "\n",
    "TRACK_SAVE_PATH = \"monza_draw.png\"\n",
    "CAR_IMAGE_PATH = \"Track_images/car.png\"\n",
    "TRACK_IMAGE_PATH = r\"Track_images\\track1.png\"\n",
    "\n",
    "finish_line_rect=pygame.Rect(DEFAULT_START_X+30,DEFAULT_START_Y-20,10,100)\n",
    "checkpoint_data=[\n",
    "    (834,520,10,120,0),\n",
    "    (600,540,10,120,0),\n",
    "    (110,569,10,120,90),\n",
    "    (285,483,10,120,0),\n",
    "    (366,314,10,120,0),\n",
    "    (355,173,10,120,0),\n",
    "    (450,109,10,120,0),\n",
    "    (606,170,10,120,0),\n",
    "    (818,91,10,120,0),\n",
    "    (1127,88,10,120,310),\n",
    "    (1094,270,10,120,0),\n",
    "    (920,346,10,120,45)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8dcd7b",
   "metadata": {},
   "source": [
    "FOR making th track drawing \n",
    "left ckick for drawing the track\n",
    "right click for eraing the track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "912d2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_track():\n",
    "    \"\"\"\n",
    "    Function to draw the racing track.\n",
    "    Left mouse button to draw, right mouse button to erase.\n",
    "    Press 'S' to save the track as an image.\n",
    "    \"\"\"\n",
    "    pygame.init()\n",
    "    pygame.display.set_caption(\"Drawing the track, press 'S' to save as image.\")\n",
    "    screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "    screen.fill(BG_COLOR)\n",
    "    running, drawing, erase = True, False, False\n",
    "    while running:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "            elif event.type == pygame.MOUSEBUTTONDOWN:\n",
    "                if event.button == 1:\n",
    "                    drawing = True\n",
    "                elif event.button == 3:\n",
    "                    erase = True\n",
    "            elif event.type == pygame.MOUSEBUTTONUP:\n",
    "                if event.button == 1:\n",
    "                    drawing = False\n",
    "                elif event.button == 3:\n",
    "                    erase = False\n",
    "            elif event.type == pygame.MOUSEMOTION:\n",
    "                mouse_pos = pygame.mouse.get_pos()\n",
    "                if drawing:\n",
    "                    pygame.draw.circle(screen, DRAW_COLOR, mouse_pos, DRAW_RADIUS)\n",
    "                elif erase:\n",
    "                    pygame.draw.circle(screen, BG_COLOR, mouse_pos, ERASE_RADIUS)\n",
    "            elif event.type == pygame.KEYDOWN and event.key == pygame.K_s:\n",
    "                pygame.image.save(screen, TRACK_SAVE_PATH)\n",
    "        pygame.display.update()\n",
    "    pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0895936",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car:\n",
    "    \"\"\"\n",
    "    Class representing a car in the racing simulation.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_path, x, y, angle=0, speed=0):\n",
    "        self.original_image = pygame.transform.scale(\n",
    "            pygame.image.load(image_path).convert_alpha(), \n",
    "            (CAR_WIDTH, CAR_HEIGHT)\n",
    "        )\n",
    "        image = pygame.image.load(image_path).convert_alpha()\n",
    "        self.image = pygame.transform.scale(image, (CAR_WIDTH, CAR_HEIGHT))\n",
    "        self.x, self.y = x, y\n",
    "        self.angle = angle\n",
    "        self.speed = speed\n",
    "        self.rect=self.image.get_rect(center=(self.x,self.y))\n",
    "        self.mask=pygame.mask.from_surface(self.image)\n",
    "\n",
    "    def move(self):\n",
    "        rad = np.radians(self.angle)\n",
    "        self.x += self.speed * np.cos(rad)\n",
    "        self.y -= self.speed * np.sin(rad)\n",
    "        self.rect.center = (self.x, self.y)\n",
    "\n",
    "    def draw(self, screen):\n",
    "        self.image = pygame.transform.rotate(self.original_image, self.angle)\n",
    "        self.rect = self.image.get_rect(center=(self.x, self.y))\n",
    "        self.mask = pygame.mask.from_surface(self.image)\n",
    "        screen.blit(self.image, self.rect.topleft)\n",
    "        \n",
    "    def get_rect(self):\n",
    "        return self.rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4346e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ray_casting(car, track_surface):\n",
    "    \"\"\"Cast rays from the car's position to detect the track boundaries.\n",
    "\n",
    "    Args:\n",
    "        car (class): The car object.\n",
    "        track_surface (Surface): The surface of the track.\n",
    "\n",
    "    Returns:\n",
    "        sensor_distance (float): The distance to the nearest track boundary.\n",
    "        sensor_endpoint (tuple): The (x, y) coordinates of the sensor endpoint.\n",
    "    \"\"\"\n",
    "    sensor_distance = []\n",
    "    sensor_endpoint = []\n",
    "    sensor_angle = [-45, 0, 45]\n",
    "\n",
    "    for angle in sensor_angle:\n",
    "        ray_angle = car.angle + angle\n",
    "        ray_x, ray_y = car.x, car.y\n",
    "        distance = 0\n",
    "        max_distance = 200\n",
    "\n",
    "        while distance < max_distance:\n",
    "            rad = np.radians(ray_angle)\n",
    "            ray_x += np.cos(rad)\n",
    "            ray_y -= np.sin(rad)\n",
    "            distance += 1\n",
    "\n",
    "            if not (0 <= ray_x < SCREEN_WIDTH and 0 <= ray_y < SCREEN_HEIGHT):\n",
    "                break\n",
    "\n",
    "            pixel_color = track_surface.get_at((int(ray_x), int(ray_y)))[0:3]\n",
    "            if pixel_color == DRAW_COLOR:\n",
    "                break\n",
    "\n",
    "        sensor_distance.append(distance)\n",
    "        sensor_endpoint.append((ray_x, ray_y))\n",
    "\n",
    "    return sensor_distance, sensor_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35516690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 32)                160       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 739\n",
      "Trainable params: 739\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def model():\n",
    "    \"\"\"Builds a simple feedforward neural network model.\n",
    "\n",
    "    Returns:\n",
    "        model: A Keras Sequential model instance.\n",
    "    \"\"\"\n",
    "    model=Sequential(\n",
    "        [Dense(32,activation='relu',input_shape=(4,)),\n",
    "         Dense(16,activation='relu'),\n",
    "         Dense(3,activation='linear')]\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model\n",
    "ai_model=model()\n",
    "ai_model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f902bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"\n",
    "    A Deep Q-Network (DQN) agent for reinforcement learning.\n",
    "    Attributes:\n",
    "        model: The neural network model used for approximating Q-values.\n",
    "        memory: A deque to store past experiences for experience replay.\n",
    "        gamma: Discount factor for future rewards.\n",
    "        epsilon: Exploration rate for the epsilon-greedy policy.\n",
    "        epsilon_min: Minimum exploration rate.\n",
    "        epsilon_decay: Decay rate for exploration after each training episode.\n",
    "        batch_size: Size of the minibatch for training.\n",
    "    Methods:\n",
    "        remember: Store an experience in memory.\n",
    "        choose_action: Select an action based on the current state using an epsilon-greedy policy.\n",
    "        train_from_memory: Train the model using a minibatch of experiences from memory.\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.memory = deque(maxlen=20000) # Increased memory size for better learning\n",
    "        self.target_model = tf.keras.models.clone_model(self.model) # Target model for stability\n",
    "        self.update_target_model() # Initialize target model\n",
    "        self.gamma = 0.95  # Discount factor: how much to value future rewards\n",
    "        self.epsilon = 1.0  # Exploration rate: initial probability of taking a random action\n",
    "        self.epsilon_min = 0.01 # Minimum exploration rate\n",
    "        self.epsilon_decay = 0.999  # Decay rate for exploration\n",
    "        self.batch_size = 128 # Increased batch size for more stable training\n",
    "        self.target_update_counter = 0 # Counter to track when to update the target model\n",
    "\n",
    "    def update_target_model(self):\n",
    "        \"\"\"Copies the weights from the main model to the target model.\"\"\"\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Stores an experience tuple in the agent's memory.\"\"\"\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        \"\"\"\n",
    "        Selects an action based on the current state using an epsilon-greedy policy.\n",
    "        With probability epsilon, it takes a random action (exploration).\n",
    "        Otherwise, it takes the best known action (exploitation).\n",
    "        \"\"\"\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(3)  # Return a random action (0, 1, 2)\n",
    "        \n",
    "        # Predict Q-values for the given state and choose the action with the highest Q-value\n",
    "        q_values = self.model.predict(np.reshape(state, [1, 4]), verbose=0)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "    def train_from_memory(self):\n",
    "        \"\"\"Train the DQN agent using experiences from memory.\n",
    "\n",
    "        Returns:\n",
    "            float: The training loss.\n",
    "        \"\"\"\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return None # Return None if not training\n",
    "\n",
    "        minibatch = random.sample(self.memory, self.batch_size)\n",
    "        states = np.array([experience[0] for experience in minibatch])\n",
    "        actions = np.array([experience[1] for experience in minibatch])\n",
    "        rewards = np.array([experience[2] for experience in minibatch])\n",
    "        next_states = np.array([experience[3] for experience in minibatch])\n",
    "        dones = np.array([experience[4] for experience in minibatch])\n",
    "\n",
    "        current_q_values = self.model.predict(states, verbose=0)\n",
    "        next_q_values = self.target_model.predict(next_states, verbose=0)\n",
    "\n",
    "        targets = rewards + self.gamma * np.amax(next_q_values, axis=1) * (1 - dones)\n",
    "        \n",
    "        for i, action in enumerate(actions):\n",
    "            current_q_values[i][action] = targets[i]\n",
    "\n",
    "        # FIX: Capture the history object to get the loss\n",
    "        history = self.model.fit(states, current_q_values, epochs=1, verbose=0)\n",
    "        loss = history.history['loss'][0]\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d40d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_game_step(action, car, track_image, current_checkpoint):\n",
    "    \"\"\"\n",
    "    Simulates a game step for the car in the racing environment.\n",
    "\n",
    "    Args:\n",
    "        action (int): Action to be taken by the car (0: left, 1: straight, 2: right, 3: brake).\n",
    "        car (Car): The car object representing the player's car.\n",
    "        track_image (Surface): The image of the track.\n",
    "        current_checkpoint (int): The index of the current checkpoint.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the new state, done flag, reward, and current checkpoint.\n",
    "    \"\"\"\n",
    "    done = False\n",
    "    \n",
    "    # --- NEW MULTI-COMPONENT REWARD SYSTEM ---\n",
    "\n",
    "    # 1. Base reward: A small penalty for each step taken. \n",
    "    # This encourages the agent to finish the lap faster.\n",
    "    reward = -0.1\n",
    "\n",
    "    # 2. Reward for Speed: Encourage the car to move forward, not stand still.\n",
    "    # The reward is proportional to its speed.\n",
    "    reward += car.speed * 0.2\n",
    "\n",
    "    # 3. Reward for Progress: This is the most important part.\n",
    "    # We get the sensor readings (the state) and reward the agent\n",
    "    # for having a clear path ahead. The middle sensor (state[1]) looks forward.\n",
    "    current_state, _ = ray_casting(car, track_image)\n",
    "    # The farther the wall, the higher the reward.\n",
    "    reward += current_state[1] * 0.005\n",
    "\n",
    "    # 4. Penalty for Sharp Turns: Discourage frantic wiggling.\n",
    "    # Encourage smoother driving by penalizing turning actions slightly.\n",
    "    if action == 0 or action == 2: # Actions for left/right turns\n",
    "        reward -= 0.2\n",
    "\n",
    "    # --- CAR PHYSICS (No changes here) ---\n",
    "    car.speed += ACCELERATION\n",
    "    if car.speed > 0:\n",
    "        speed_factor = car.speed / MAX_SPEED\n",
    "        dynamic_turn_angle = MAX_TURN_ANGLE - (speed_factor) * (MAX_TURN_ANGLE - MIN_TURN_ANGLE)\n",
    "        if action == 0:  # Left\n",
    "            car.angle += dynamic_turn_angle\n",
    "        elif action == 1:  # Right\n",
    "            car.angle -= dynamic_turn_angle\n",
    "    \n",
    "    if action == 2: # Brake\n",
    "        car.speed -= BRAKE_FORCE\n",
    "    \n",
    "    car.speed -= FRICTION\n",
    "    car.speed = max(0, min(car.speed, MAX_SPEED))\n",
    "    car.move()\n",
    "    \n",
    "    # --- GOAL-BASED REWARDS (Checkpoints and Crashing) ---\n",
    "    checkpoint_rects = [pygame.Rect(x, y, w, h) for x, y, w, h, a in checkpoint_data]\n",
    "    \n",
    "    # 5. Large reward for hitting a checkpoint.\n",
    "    if current_checkpoint < len(checkpoint_rects):\n",
    "        if car.rect.colliderect(checkpoint_rects[current_checkpoint]):\n",
    "            current_checkpoint += 1\n",
    "            reward += 100 # Large positive reward\n",
    "            print(f\"Checkpoint {current_checkpoint} reached!\")\n",
    "\n",
    "    # 6. Very large reward for finishing the lap.\n",
    "    if current_checkpoint == len(checkpoint_rects) and car.rect.colliderect(finish_line_rect):\n",
    "        reward += 300\n",
    "        current_checkpoint = 0\n",
    "        print(\"Lap finished!\")\n",
    "\n",
    "    # 7. Large penalty for crashing.\n",
    "    try:\n",
    "        pixel_color = track_image.get_at((int(car.x), int(car.y)))[:3]\n",
    "        if pixel_color == DRAW_COLOR:\n",
    "            done = True\n",
    "    except IndexError:\n",
    "        done = True\n",
    "        \n",
    "    if done:\n",
    "        reward = -20 # Keep a significant penalty for crashing, but not as extreme as -100\n",
    "\n",
    "    new_state, _ = ray_casting(car, track_image)\n",
    "    return new_state, done, reward, current_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbe761f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn(episodes=500):\n",
    "    \"\"\"\n",
    "    Main function to train the DQN agent with enhanced logging and plotting.\n",
    "    \"\"\"\n",
    "    pygame.init()\n",
    "    screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT)) # Keep commented out for speed\n",
    "    track_surface = pygame.image.load(TRACK_IMAGE_PATH).convert()\n",
    "    \n",
    "    ai_model = model()\n",
    "    agent = DQNAgent(ai_model)\n",
    "\n",
    "    # NEW: Add lists to store history for new plots\n",
    "    scores_history = []\n",
    "    loss_history = []\n",
    "    checkpoints_history = []\n",
    "    max_speed_history = []\n",
    "    \n",
    "    for e in range(episodes):\n",
    "        car = Car(CAR_IMAGE_PATH, DEFAULT_START_X, DEFAULT_START_Y, DEFAULT_START_ANGLE, DEFAULT_START_SPEED)\n",
    "        current_checkpoint = 0\n",
    "        \n",
    "        distances, _ = ray_casting(car, track_surface)\n",
    "        speed = car.speed / MAX_SPEED \n",
    "        state = np.array(distances + [speed]) \n",
    "        state = np.reshape(state, [1, 4])\n",
    "        \n",
    "        total_reward = 0\n",
    "        max_steps_per_episode = 2000\n",
    "        max_speed_episode = 0\n",
    "\n",
    "        for step in range(max_steps_per_episode):\n",
    "            action = agent.choose_action(state)\n",
    "            distances_next, done, reward, new_checkpoint = model_game_step(action, car, track_surface, current_checkpoint)\n",
    "            \n",
    "            max_speed_episode = max(max_speed_episode, car.speed)\n",
    "            \n",
    "            total_reward += reward\n",
    "            speed_next = car.speed / MAX_SPEED \n",
    "            next_state = np.array(distances_next + [speed_next])\n",
    "            next_state = np.reshape(next_state, [1, 4])\n",
    "            current_checkpoint = new_checkpoint\n",
    "            \n",
    "            agent.remember(state[0], action, reward, next_state[0], done)\n",
    "            state = next_state\n",
    "            \n",
    "            if step % 4 == 0: # Train every 8 steps for speed\n",
    "                loss = agent.train_from_memory()\n",
    "                if loss is not None:\n",
    "                    loss_history.append(loss)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        if e % 5 == 0:\n",
    "            agent.update_target_model()\n",
    "            print(f\"--- Target Network Updated at Episode {e+1} ---\")\n",
    "            \n",
    "        # NEW: Append the new metrics to their history lists\n",
    "        scores_history.append(total_reward)\n",
    "        checkpoints_history.append(current_checkpoint)\n",
    "        max_speed_history.append(max_speed_episode)\n",
    "        \n",
    "        print(\n",
    "            f\"Episode: {e+1}/{episodes}, \"\n",
    "            f\"Score: {total_reward:.2f}, \"\n",
    "            f\"Max Speed: {max_speed_episode:.2f}, \"\n",
    "            f\"Checkpoints: {current_checkpoint}, \"\n",
    "            f\"Epsilon: {agent.epsilon:.2f}\"\n",
    "        )\n",
    "\n",
    "        if (e + 1) % 50 == 0:\n",
    "            ai_model.save_weights(f\"dqn_car_weights_episode_{e+1}.weights.h5\")\n",
    "\n",
    "    pygame.quit()\n",
    "\n",
    "# --- MODIFIED: Enhanced plotting section with Bar Chart ---\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    \n",
    "    # NEW: Create 4 subplots instead of 3, and increase the figure size\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(12, 22)) \n",
    "\n",
    "    # --- Graph 1: Score ---\n",
    "    ax1.set_title('Agent Score Over Time')\n",
    "    ax1.set_xlabel('Episode')\n",
    "    ax1.set_ylabel('Total Reward (Score)')\n",
    "    ax1.plot(scores_history, label='Score per Episode', color='royalblue')\n",
    "    ax1.legend()\n",
    "\n",
    "    # --- Graph 2: Max Speed ---\n",
    "    ax2.set_title('Max Speed Achieved per Episode')\n",
    "    ax2.set_xlabel('Episode')\n",
    "    ax2.set_ylabel('Max Speed')\n",
    "    ax2.plot(max_speed_history, label='Max Speed', color='purple')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # --- Graph 3: Model Loss ---\n",
    "    ax3.set_title('Model Loss Over Time')\n",
    "    ax3.set_xlabel('Training Step')\n",
    "    ax3.set_ylabel('MSE Loss')\n",
    "    ax3.plot(loss_history, label='Training Loss', color='orangered', alpha=0.7)\n",
    "    ax3.legend()\n",
    "\n",
    "    # --- NEW: Graph 4: Checkpoints Bar Chart ---\n",
    "    ax4.set_title('Checkpoints Cleared per Episode')\n",
    "    ax4.set_xlabel('Episode')\n",
    "    ax4.set_ylabel('Checkpoints Cleared')\n",
    "    # Use ax4.bar() to create the bar chart\n",
    "    episodes = range(len(checkpoints_history))\n",
    "    ax4.bar(episodes, checkpoints_history, color='forestgreen', label='Checkpoints')\n",
    "    # Set y-axis to be integers since you can't clear half a checkpoint\n",
    "    ax4.yaxis.set_major_locator(plt.MaxNLocator(integer=True)) \n",
    "    ax4.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # --- Optional: Add a histogram for checkpoint distribution ---\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title('Distribution of Checkpoints Cleared')\n",
    "    plt.xlabel('Number of Checkpoints Cleared in an Episode')\n",
    "    plt.ylabel('Number of Episodes')\n",
    "    plt.hist(checkpoints_history, bins=range(max(checkpoints_history) + 2), align='left', rwidth=0.8)\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af0f3dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ai_simulation():\n",
    "    \"\"\"Runs the car simulation controlled by an AI model.\n",
    "        The AI model predicts actions based on the car's sensor data.\n",
    "        0: turn left\n",
    "        1: accelerate\n",
    "        2: turn right\n",
    "        3: brake\n",
    "    \"\"\"\n",
    "    pygame.init()\n",
    "    screen=pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "    clock=pygame.time.Clock()\n",
    "    pygame.display.set_caption(\"AI Car Simulation\")\n",
    "    track_surface=pygame.image.load(TRACK_IMAGE_PATH).convert()\n",
    "    car=Car(CAR_IMAGE_PATH,DEFAULT_START_X,DEFAULT_START_Y,DEFAULT_START_ANGLE,DEFAULT_START_SPEED)\n",
    "    font=pygame.font.SysFont(None,22)\n",
    "    \n",
    "    running=True\n",
    "    while running:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type==pygame.QUIT:\n",
    "                running=False\n",
    "        current_state,ray_endpoints=ray_casting(car,track_surface)\n",
    "        reshaped_state = np.reshape(current_state, [1, 3])\n",
    "        q_values = ai_model.predict(reshaped_state, verbose=0)\n",
    "        action = np.argmax(q_values[0])\n",
    "        _ ,_ ,done=model_game_step(action,car,track_surface)\n",
    "        if done:\n",
    "            text_surface = font.render(\"Car Crashed! Resetting...\", True, (255, 255, 255))\n",
    "            screen.blit(text_surface, (50, 50))\n",
    "            pygame.display.update()\n",
    "            pygame.time.wait(1000)\n",
    "            car=Car(CAR_IMAGE_PATH,DEFAULT_START_X,DEFAULT_START_Y,DEFAULT_START_ANGLE,DEFAULT_START_SPEED)\n",
    "        \n",
    "        screen.blit(track_surface,(0,0))\n",
    "        car.draw(screen)\n",
    "        \n",
    "        text_surface = font.render(f\"Distances: {current_state}\", True, (255, 255, 255))\n",
    "        screen.blit(text_surface, (50, 80))\n",
    "        for points in ray_endpoints:\n",
    "            pygame.draw.line(screen,(0,255,0),(car.x,car.y),points,1)\n",
    "            \n",
    "        pygame.display.update()\n",
    "        clock.tick(60)\n",
    "    pygame.quit()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e04541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(\n",
    "    start_x=DEFAULT_START_X,\n",
    "    start_y=DEFAULT_START_Y,\n",
    "    start_angle=DEFAULT_START_ANGLE,\n",
    "    start_speed=DEFAULT_START_SPEED\n",
    "):\n",
    "    \"\"\"Runs the car simulation manually by the user.\n",
    "\n",
    "    Args:\n",
    "        start_x (int, optional): The starting x-coordinate of the car. Defaults to DEFAULT_START_X.\n",
    "        start_y (int, optional): The starting y-coordinate of the car. Defaults to DEFAULT_START_Y.\n",
    "        start_angle (float, optional): The starting angle of the car. Defaults to DEFAULT_START_ANGLE.\n",
    "        start_speed (float, optional): The starting speed of the car. Defaults to DEFAULT_START_SPEED.\n",
    "    \"\"\"\n",
    "    pygame.init()\n",
    "    screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "    clock = pygame.time.Clock()\n",
    "    pygame.display.set_caption(\"Car Simulation\")\n",
    "\n",
    "    track_image = pygame.image.load(TRACK_IMAGE_PATH).convert()\n",
    "    track_surface = track_image.copy()\n",
    "\n",
    "    car = Car(CAR_IMAGE_PATH, start_x, start_y, start_angle, start_speed)\n",
    "\n",
    "    screen.fill(BG_COLOR)\n",
    "    screen.blit(track_image, (0, 0))\n",
    "\n",
    "    CAR_ROAD_COLOR = track_surface.get_at((start_x, start_y))[:3]\n",
    "\n",
    "  \n",
    "\n",
    "    lap_start_time=0\n",
    "    best_lap_time=float('inf')\n",
    "    current_lap_time=0\n",
    "    lap_started=False\n",
    "    car_on_finish=False\n",
    "\n",
    "    car_max_speed = 0\n",
    "    \n",
    "    #checkpoints\n",
    "    checkpoints=[]\n",
    "    \n",
    "    for x,y,w,h,a in checkpoint_data:\n",
    "        base_surface=pygame.Surface((w,h),pygame.SRCALPHA)\n",
    "        base_surface.fill((255,0,255,100))\n",
    "        rotated_surface=pygame.transform.rotate(base_surface,a)\n",
    "        rect=rotated_surface.get_rect(center=(x,y))\n",
    "        mask=pygame.mask.from_surface(rotated_surface)\n",
    "        checkpoints.append({'surface': rotated_surface, 'rect': rect, 'mask': mask})\n",
    "    current_checkpoint=0\n",
    "\n",
    "    running = True\n",
    "    while running:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "        keys = pygame.key.get_pressed()\n",
    "        if car.speed > 0:\n",
    "            car.speed -= FRICTION\n",
    "        if car.speed < 0:\n",
    "            car.speed += FRICTION\n",
    "        if abs(car.speed) < FRICTION:\n",
    "            car.speed = 0\n",
    "        if keys[pygame.K_DOWN]:\n",
    "            car.speed -= BRAKE_FORCE\n",
    "        if keys[pygame.K_UP]:\n",
    "            if car.speed < MAX_SPEED:\n",
    "                car.speed += ACCELERATION\n",
    "                \n",
    "        if car.speed > 0.1:\n",
    "            speed_factor = car.speed / MAX_SPEED\n",
    "            turn_range = MAX_TURN_ANGLE - MIN_TURN_ANGLE\n",
    "            dynamic_turn_angle = MAX_TURN_ANGLE - (speed_factor * turn_range)\n",
    "        \n",
    "            if keys[pygame.K_LEFT]:\n",
    "                car.angle += dynamic_turn_angle\n",
    "            if keys[pygame.K_RIGHT]:\n",
    "                car.angle -= dynamic_turn_angle\n",
    "\n",
    "        screen.blit(track_image, (0, 0))\n",
    "\n",
    "        font = pygame.font.Font(None, 22)\n",
    "        text_surface = font.render(f\"Speed: {car.speed:.2f}\", True, (255, 255, 255))\n",
    "        screen.blit(text_surface, (50, 50))\n",
    "\n",
    "        # Ray casting\n",
    "        distance, sensor_endpoint = ray_casting(car, track_surface)\n",
    "        text_surface = font.render(f\"Distances: {distance}\", True, (255, 255, 255))\n",
    "        screen.blit(text_surface, (50, 80))\n",
    "        for endpoint in sensor_endpoint:\n",
    "            pygame.draw.line(screen, (0, 255, 0), (car.x, car.y), endpoint, 1)\n",
    "\n",
    "        car.move()\n",
    "        \n",
    "        #cheking checkpoints\n",
    "        if current_checkpoint < len(checkpoints):\n",
    "            target = checkpoints[current_checkpoint]\n",
    "\n",
    "            # compute offset of target mask relative to car mask\n",
    "            offset_x = target['rect'].left - car.rect.left\n",
    "            offset_y = target['rect'].top  - car.rect.top\n",
    "\n",
    "\n",
    "            if (offset_y==0 and -60<offset_x<60) or (offset_x==0 and -60<offset_y<60):\n",
    "                current_checkpoint += 1\n",
    "                print(f\"Checkpoint reached! {current_checkpoint}\")\n",
    "\n",
    "        \n",
    "        car.draw(screen)\n",
    "        \n",
    "        for i, cp in enumerate(checkpoints):\n",
    "          screen.blit(cp['surface'], cp['rect'])\n",
    "          if i == current_checkpoint:\n",
    "              pygame.draw.rect(screen, (0, 255, 0), cp['rect'], 3)\n",
    "        \n",
    "        #lap timing (collision detection)\n",
    "        is_colliding=car.get_rect().colliderect(finish_line_rect)\n",
    "        if is_colliding and not car_on_finish:\n",
    "            car_on_finish=True\n",
    "            if lap_started and current_checkpoint == len(checkpoints):\n",
    "                lap_time=time.time()-lap_start_time\n",
    "                best_lap_time=min(best_lap_time,lap_time)\n",
    "                lap_start_time=time.time()\n",
    "                current_checkpoint=0\n",
    "            elif not lap_started:\n",
    "                lap_started = True\n",
    "                lap_start_time = time.time()\n",
    "                current_checkpoint = 0\n",
    "        if not is_colliding:\n",
    "            car_on_finish=False\n",
    "            \n",
    "        pygame.draw.rect(screen, (250, 100, 50), finish_line_rect)\n",
    "        \n",
    "\n",
    "        # Collision detection (including out-of-bounds)\n",
    "        crashed = False\n",
    "        car_center_pos = (int(car.x), int(car.y))\n",
    "        if not (0 <= car.x < SCREEN_WIDTH and 0 <= car.y < SCREEN_HEIGHT):\n",
    "            crashed = True\n",
    "        else:\n",
    "            try:\n",
    "                pixel_color = track_surface.get_at(car_center_pos)[:3]\n",
    "                if pixel_color != CAR_ROAD_COLOR:\n",
    "                    crashed = True\n",
    "            except IndexError:\n",
    "                crashed = True\n",
    "\n",
    "        if crashed:\n",
    "            lap_started=False\n",
    "            current_lap_time=0 \n",
    "            current_checkpoint=0\n",
    "            text_surface = font.render(\"Car has crashed!\", True, (255, 255, 255))\n",
    "            screen.blit(text_surface, (50, 110))\n",
    "            pygame.display.update()\n",
    "            pygame.time.wait(1000)  # Show message for 1 second\n",
    "            car.x, car.y = start_x, start_y\n",
    "            car.angle = start_angle\n",
    "            car.speed = start_speed\n",
    "\n",
    "        if car.speed > car_max_speed:\n",
    "            car_max_speed = car.speed\n",
    "\n",
    "        if lap_started:\n",
    "            current_lap_time = time.time() - lap_start_time\n",
    "            current_lap_str = f\"Lap: {current_lap_time:.2f}s\"\n",
    "        else:\n",
    "            current_lap_str = \"Lap: 0.00s\"                                           \n",
    "        best_lap_str = f\"Best: {best_lap_time:.2f}s\" if best_lap_time != float('inf') else \"Best: N/A\"\n",
    "        text_surface = font.render(current_lap_str, True, (255, 255, 255))            \n",
    "        screen.blit(text_surface, (50, 500))\n",
    "        best_text = font.render(best_lap_str, True, (255, 255, 255))\n",
    "        screen.blit(best_text, (50, 530))\n",
    "        text_surface = font.render(f\"Max speed: {car_max_speed:.2f}\", True, (255, 255, 255))\n",
    "        screen.blit(text_surface, (50, 470))\n",
    "\n",
    "        pygame.display.update()\n",
    "        clock.tick(60)\n",
    "\n",
    "    pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07ea071",
   "metadata": {},
   "source": [
    "        if event.type == pygame.MOUSEMOTION:\n",
    "            mouse_point = event.pos\n",
    "            text_surface = font.render(f\"Location: {mouse_point}\", True, (255, 255, 255))\n",
    "            screen.blit(text_surface, (50, 100))\n",
    " #code for getting mouse location\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "823c5ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Target Network Updated at Episode 1 ---\n",
      "Episode: 1/50, Score: 103.21, Max Speed: 0.55, Checkpoints: 0, Epsilon: 0.97\n",
      "Episode: 2/50, Score: 146.67, Max Speed: 0.35, Checkpoints: 0, Epsilon: 0.89\n",
      "Episode: 3/50, Score: 98.35, Max Speed: 0.35, Checkpoints: 0, Epsilon: 0.83\n",
      "Episode: 4/50, Score: 44.28, Max Speed: 0.50, Checkpoints: 0, Epsilon: 0.79\n",
      "Checkpoint 1 reached!\n",
      "Episode: 5/50, Score: 1248.44, Max Speed: 1.23, Checkpoints: 1, Epsilon: 0.59\n",
      "--- Target Network Updated at Episode 6 ---\n",
      "Episode: 6/50, Score: 2278.12, Max Speed: 1.80, Checkpoints: 0, Epsilon: 0.36\n",
      "Episode: 7/50, Score: 2443.35, Max Speed: 2.60, Checkpoints: 0, Epsilon: 0.22\n",
      "Episode: 8/50, Score: 2628.89, Max Speed: 0.25, Checkpoints: 0, Epsilon: 0.13\n",
      "Episode: 9/50, Score: 2655.59, Max Speed: 0.10, Checkpoints: 0, Epsilon: 0.08\n",
      "Episode: 10/50, Score: 2615.53, Max Speed: 0.08, Checkpoints: 0, Epsilon: 0.05\n",
      "--- Target Network Updated at Episode 11 ---\n",
      "Episode: 11/50, Score: 2699.72, Max Speed: 0.08, Checkpoints: 0, Epsilon: 0.03\n",
      "Episode: 12/50, Score: 2697.97, Max Speed: 0.23, Checkpoints: 0, Epsilon: 0.02\n",
      "Episode: 13/50, Score: 2717.94, Max Speed: 0.10, Checkpoints: 0, Epsilon: 0.01\n",
      "Episode: 14/50, Score: 2760.56, Max Speed: 0.10, Checkpoints: 0, Epsilon: 0.01\n",
      "Episode: 15/50, Score: 2724.34, Max Speed: 0.08, Checkpoints: 0, Epsilon: 0.01\n",
      "--- Target Network Updated at Episode 16 ---\n",
      "Episode: 16/50, Score: 2755.09, Max Speed: 0.13, Checkpoints: 0, Epsilon: 0.01\n",
      "Episode: 17/50, Score: 111.25, Max Speed: 2.93, Checkpoints: 0, Epsilon: 0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m#draw_track()\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#run_simulation()\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# run_ai_simulation()\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mtrain_dqn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 47\u001b[0m, in \u001b[0;36mtrain_dqn\u001b[1;34m(episodes)\u001b[0m\n\u001b[0;32m     44\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m# Train every 8 steps for speed\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_from_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m         loss_history\u001b[38;5;241m.\u001b[39mappend(loss)\n",
      "Cell \u001b[1;32mIn[19], line 59\u001b[0m, in \u001b[0;36mDQNAgent.train_from_memory\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# Return None if not training\u001b[39;00m\n\u001b[0;32m     58\u001b[0m minibatch \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[1;32m---> 59\u001b[0m states \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexperience\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexperience\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mminibatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([experience[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m experience \u001b[38;5;129;01min\u001b[39;00m minibatch])\n\u001b[0;32m     61\u001b[0m rewards \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([experience[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m experience \u001b[38;5;129;01min\u001b[39;00m minibatch])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #draw_track()\n",
    "    #run_simulation()\n",
    "    # run_ai_simulation()\n",
    "    train_dqn(episodes=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a12d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RUNNING VISUAL SANITY CHECK ---\n",
      "Initial Car Position: (900.00, 426.00)\n",
      "Is the car on the track? Look at the screen.\n",
      "\n",
      "Taking ONE random action: Brake\n",
      "Position after one move: (900.00, 426.00)\n",
      "Did it crash? (done = False)\n",
      "\n",
      ">>> TEST PASSED: The car survived its first move.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"--- RUNNING VISUAL SANITY CHECK ---\")\n",
    "    \n",
    "    # 1. Setup the environment\n",
    "    pygame.init()\n",
    "    screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "    track_surface = pygame.image.load(TRACK_IMAGE_PATH).convert()\n",
    "    \n",
    "    # 2. Place the car at its starting position\n",
    "    car = Car(CAR_IMAGE_PATH, DEFAULT_START_X, DEFAULT_START_Y, DEFAULT_START_ANGLE, DEFAULT_START_SPEED)\n",
    "\n",
    "    # 3. Draw the initial state\n",
    "    screen.blit(track_surface, (0, 0))\n",
    "    car.draw(screen)\n",
    "    pygame.display.update()\n",
    "    \n",
    "    print(f\"Initial Car Position: ({car.x:.2f}, {car.y:.2f})\")\n",
    "    print(\"Is the car on the track? Look at the screen.\")\n",
    "    time.sleep(5) # PAUSE FOR 5 SECONDS TO LET YOU SEE\n",
    "\n",
    "    # 4. Take ONE random action\n",
    "    action = random.randrange(3)\n",
    "    print(f\"\\nTaking ONE random action: {['Left', 'Right', 'Brake'][action]}\")\n",
    "    _, done, _, _ = model_game_step(action, car, track_surface, 0)\n",
    "\n",
    "    # 5. Draw the state AFTER one move\n",
    "    screen.blit(track_surface, (0, 0))\n",
    "    car.draw(screen)\n",
    "    pygame.display.update()\n",
    "\n",
    "    print(f\"Position after one move: ({car.x:.2f}, {car.y:.2f})\")\n",
    "    print(f\"Did it crash? (done = {done})\")\n",
    "    if done:\n",
    "        print(\"\\n>>> TEST FAILED: The car crashed on its very first move!\")\n",
    "    else:\n",
    "        print(\"\\n>>> TEST PASSED: The car survived its first move.\")\n",
    "\n",
    "    time.sleep(5) # PAUSE AGAIN\n",
    "    pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a339f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2b6a61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
