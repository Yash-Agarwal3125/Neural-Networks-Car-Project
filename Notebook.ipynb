{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5d622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os         \n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"    # To run pygame without a display (for headless environments)\n",
    "\n",
    "#required libraries\n",
    "import numpy as np\n",
    "import pygame           \n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import time\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e17ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global constants\n",
    "\n",
    "SCREEN_WIDTH, SCREEN_HEIGHT = 1280, 720\n",
    "BG_COLOR = (120, 120, 120)\n",
    "DRAW_COLOR = (50, 50, 50)\n",
    "\n",
    "DRAW_RADIUS = 2\n",
    "ERASE_RADIUS = 5  \n",
    "\n",
    "CAR_WIDTH, CAR_HEIGHT = 20, 40\n",
    "DEFAULT_START_X, DEFAULT_START_Y = 900, 426\n",
    "DEFAULT_START_ANGLE = -45\n",
    "DEFAULT_START_SPEED = 0\n",
    "ACCELERATION = 0.05\n",
    "BRAKE_FORCE = 0.1\n",
    "MAX_SPEED = 5.00\n",
    "FRICTION = 0.025\n",
    "MIN_TURN_ANGLE = 1.5\n",
    "MAX_TURN_ANGLE = 2\n",
    "\n",
    "TRACK_SAVE_PATH = \"monza_draw.png\"\n",
    "CAR_IMAGE_PATH = \"Track_images/car.png\"\n",
    "TRACK_IMAGE_PATH = r\"Track_images\\track1.png\"\n",
    "\n",
    "finish_line_rect=pygame.Rect(DEFAULT_START_X+30,DEFAULT_START_Y-20,10,100)\n",
    "checkpoint_data=[\n",
    "    (834,520,10,120,0),\n",
    "    (600,540,10,120,0),\n",
    "    (110,569,10,120,90),\n",
    "    (285,483,10,120,0),\n",
    "    (366,314,10,120,0),\n",
    "    (355,173,10,120,0),\n",
    "    (450,109,10,120,0),\n",
    "    (606,170,10,120,0),\n",
    "    (818,91,10,120,0),\n",
    "    (1127,88,10,120,310),\n",
    "    (1094,270,10,120,0),\n",
    "    (920,346,10,120,45)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8dcd7b",
   "metadata": {},
   "source": [
    "FOR making th track drawing \n",
    "left ckick for drawing the track\n",
    "right click for eraing the track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912d2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_track():\n",
    "    \"\"\"\n",
    "    Function to draw the racing track.\n",
    "    Left mouse button to draw, right mouse button to erase.\n",
    "    Press 'S' to save the track as an image.\n",
    "    \"\"\"\n",
    "    pygame.init()\n",
    "    pygame.display.set_caption(\"Drawing the track, press 'S' to save as image.\")\n",
    "    screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "    screen.fill(BG_COLOR)\n",
    "    running, drawing, erase = True, False, False\n",
    "    while running:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "            elif event.type == pygame.MOUSEBUTTONDOWN:\n",
    "                if event.button == 1:\n",
    "                    drawing = True\n",
    "                elif event.button == 3:\n",
    "                    erase = True\n",
    "            elif event.type == pygame.MOUSEBUTTONUP:\n",
    "                if event.button == 1:\n",
    "                    drawing = False\n",
    "                elif event.button == 3:\n",
    "                    erase = False\n",
    "            elif event.type == pygame.MOUSEMOTION:\n",
    "                mouse_pos = pygame.mouse.get_pos()\n",
    "                if drawing:\n",
    "                    pygame.draw.circle(screen, DRAW_COLOR, mouse_pos, DRAW_RADIUS)\n",
    "                elif erase:\n",
    "                    pygame.draw.circle(screen, BG_COLOR, mouse_pos, ERASE_RADIUS)\n",
    "            elif event.type == pygame.KEYDOWN and event.key == pygame.K_s:\n",
    "                pygame.image.save(screen, TRACK_SAVE_PATH)\n",
    "        pygame.display.update()\n",
    "    pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0895936",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car:\n",
    "    \"\"\"\n",
    "    Class representing a car in the racing simulation.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_path, x, y, angle=0, speed=0):\n",
    "        self.original_image = pygame.transform.scale(\n",
    "            pygame.image.load(image_path).convert_alpha(), \n",
    "            (CAR_WIDTH, CAR_HEIGHT)\n",
    "        )\n",
    "        image = pygame.image.load(image_path).convert_alpha()\n",
    "        self.image = pygame.transform.scale(image, (CAR_WIDTH, CAR_HEIGHT))\n",
    "        self.x, self.y = x, y\n",
    "        self.angle = angle\n",
    "        self.speed = speed\n",
    "        self.rect=self.image.get_rect(center=(self.x,self.y))\n",
    "        self.mask=pygame.mask.from_surface(self.image)\n",
    "\n",
    "    def move(self):\n",
    "        rad = np.radians(self.angle)\n",
    "        self.x += self.speed * np.cos(rad)\n",
    "        self.y -= self.speed * np.sin(rad)\n",
    "        self.rect.center = (self.x, self.y)\n",
    "\n",
    "    def draw(self, screen):\n",
    "        self.image = pygame.transform.rotate(self.original_image, self.angle)\n",
    "        self.rect = self.image.get_rect(center=(self.x, self.y))\n",
    "        self.mask = pygame.mask.from_surface(self.image)\n",
    "        screen.blit(self.image, self.rect.topleft)\n",
    "        \n",
    "    def get_rect(self):\n",
    "        return self.rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4346e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ray_casting(car, track_surface):\n",
    "    \"\"\"Cast rays from the car's position to detect the track boundaries.\n",
    "\n",
    "    Args:\n",
    "        car (class): The car object.\n",
    "        track_surface (Surface): The surface of the track.\n",
    "\n",
    "    Returns:\n",
    "        sensor_distance (float): The distance to the nearest track boundary.\n",
    "        sensor_endpoint (tuple): The (x, y) coordinates of the sensor endpoint.\n",
    "    \"\"\"\n",
    "    sensor_distance = []\n",
    "    sensor_endpoint = []\n",
    "    sensor_angle = [-45, 0, 45]\n",
    "\n",
    "    for angle in sensor_angle:\n",
    "        ray_angle = car.angle + angle\n",
    "        ray_x, ray_y = car.x, car.y\n",
    "        distance = 0\n",
    "        max_distance = 200\n",
    "\n",
    "        while distance < max_distance:\n",
    "            rad = np.radians(ray_angle)\n",
    "            ray_x += np.cos(rad)\n",
    "            ray_y -= np.sin(rad)\n",
    "            distance += 1\n",
    "\n",
    "            if not (0 <= ray_x < SCREEN_WIDTH and 0 <= ray_y < SCREEN_HEIGHT):\n",
    "                break\n",
    "\n",
    "            pixel_color = track_surface.get_at((int(ray_x), int(ray_y)))[0:3]\n",
    "            if pixel_color == DRAW_COLOR:\n",
    "                break\n",
    "\n",
    "        sensor_distance.append(distance)\n",
    "        sensor_endpoint.append((ray_x, ray_y))\n",
    "\n",
    "    return sensor_distance, sensor_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35516690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    \"\"\"Builds a simple feedforward neural network model.\n",
    "\n",
    "    Returns:\n",
    "        model: A Keras Sequential model instance.\n",
    "    \"\"\"\n",
    "    model=Sequential(\n",
    "        [Dense(32,activation='relu',input_shape=(4,)),\n",
    "         Dense(16,activation='relu'),\n",
    "         Dense(3,activation='linear')]\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model\n",
    "ai_model=model()\n",
    "ai_model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f902bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"\n",
    "    A Deep Q-Network (DQN) agent for reinforcement learning.\n",
    "    Attributes:\n",
    "        model: The neural network model used for approximating Q-values.\n",
    "        memory: A deque to store past experiences for experience replay.\n",
    "        gamma: Discount factor for future rewards.\n",
    "        epsilon: Exploration rate for the epsilon-greedy policy.\n",
    "        epsilon_min: Minimum exploration rate.\n",
    "        epsilon_decay: Decay rate for exploration after each training episode.\n",
    "        batch_size: Size of the minibatch for training.\n",
    "    Methods:\n",
    "        remember: Store an experience in memory.\n",
    "        choose_action: Select an action based on the current state using an epsilon-greedy policy.\n",
    "        train_from_memory: Train the model using a minibatch of experiences from memory.\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.memory = deque(maxlen=20000) # Increased memory size for better learning\n",
    "        self.target_model = tf.keras.models.clone_model(self.model) # Target model for stability\n",
    "        self.update_target_model() # Initialize target model\n",
    "        self.gamma = 0.95  # Discount factor: how much to value future rewards\n",
    "        self.epsilon = 1.0  # Exploration rate: initial probability of taking a random action\n",
    "        self.epsilon_min = 0.01 # Minimum exploration rate\n",
    "        self.epsilon_decay = 0.999  # Decay rate for exploration\n",
    "        self.batch_size = 128 # Increased batch size for more stable training\n",
    "        self.target_update_counter = 0 # Counter to track when to update the target model\n",
    "\n",
    "    def update_target_model(self):\n",
    "        \"\"\"Copies the weights from the main model to the target model.\"\"\"\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Stores an experience tuple in the agent's memory.\"\"\"\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        \"\"\"\n",
    "        Selects an action based on the current state using an epsilon-greedy policy.\n",
    "        With probability epsilon, it takes a random action (exploration).\n",
    "        Otherwise, it takes the best known action (exploitation).\n",
    "        \"\"\"\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(3)  # Return a random action (0, 1, 2)\n",
    "        \n",
    "        # Predict Q-values for the given state and choose the action with the highest Q-value\n",
    "        q_values = self.model.predict(np.reshape(state, [1, 4]), verbose=0)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "    def train_from_memory(self):\n",
    "        \"\"\"Train the DQN agent using experiences from memory.\n",
    "\n",
    "        Returns:\n",
    "            float: The training loss.\n",
    "        \"\"\"\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return None # Return None if not training\n",
    "\n",
    "        minibatch = random.sample(self.memory, self.batch_size)\n",
    "        states = np.array([experience[0] for experience in minibatch])\n",
    "        actions = np.array([experience[1] for experience in minibatch])\n",
    "        rewards = np.array([experience[2] for experience in minibatch])\n",
    "        next_states = np.array([experience[3] for experience in minibatch])\n",
    "        dones = np.array([experience[4] for experience in minibatch])\n",
    "\n",
    "        current_q_values = self.model.predict(states, verbose=0)\n",
    "        next_q_values = self.target_model.predict(next_states, verbose=0)\n",
    "\n",
    "        targets = rewards + self.gamma * np.amax(next_q_values, axis=1) * (1 - dones)\n",
    "        \n",
    "        for i, action in enumerate(actions):\n",
    "            current_q_values[i][action] = targets[i]\n",
    "\n",
    "        # FIX: Capture the history object to get the loss\n",
    "        history = self.model.fit(states, current_q_values, epochs=1, verbose=0)\n",
    "        loss = history.history['loss'][0]\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d40d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_game_step(action, car, track_image, current_checkpoint):\n",
    "    \"\"\"\n",
    "    Simulates a game step for the car in the racing environment.\n",
    "\n",
    "    Args:\n",
    "        action (int): Action to be taken by the car (0: left, 1: straight, 2: right, 3: brake).\n",
    "        car (Car): The car object representing the player's car.\n",
    "        track_image (Surface): The image of the track.\n",
    "        current_checkpoint (int): The index of the current checkpoint.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the new state, done flag, reward, and current checkpoint.\n",
    "    \"\"\"\n",
    "    done = False\n",
    "    \n",
    "    # --- NEW MULTI-COMPONENT REWARD SYSTEM ---\n",
    "\n",
    "    # 1. Base reward: A small penalty for each step taken. \n",
    "    # This encourages the agent to finish the lap faster.\n",
    "    reward = -0.5\n",
    "    \n",
    "    if car.speed < 0.3:\n",
    "        reward -= 2  # Extra penalty for being too slow\n",
    "\n",
    "    # 2. Reward for Speed: Encourage the car to move forward, not stand still.\n",
    "    # The reward is proportional to its speed.\n",
    "    reward += car.speed * 0.5\n",
    "\n",
    "    # 3. Reward for Progress: This is the most important part.\n",
    "    # We get the sensor readings (the state) and reward the agent\n",
    "    # for having a clear path ahead. The middle sensor (state[1]) looks forward.\n",
    "    current_state, _ = ray_casting(car, track_image)\n",
    "    # The farther the wall, the higher the reward.\n",
    "    reward += current_state[1] * 0.01\n",
    "    \n",
    "    is_turning = action == 0 or action == 1\n",
    "    is_braking = action == 2\n",
    "    if is_turning and car.speed > (MAX_SPEED * 0.5): # Encourage braking only at high speeds.\n",
    "        if is_braking:\n",
    "            reward += 1.0 # Reward for braking in a turn.\n",
    "\n",
    "    # 4. Penalty for Sharp Turns: Discourage frantic wiggling.\n",
    "    # Encourage smoother driving by penalizing turning actions slightly.\n",
    "    if action == 0: # Actions for left turns\n",
    "        reward -= 0.2\n",
    "\n",
    "    # --- CAR PHYSICS (No changes here) ---\n",
    "    car.speed += ACCELERATION\n",
    "    if car.speed > 0:\n",
    "        speed_factor = car.speed / MAX_SPEED\n",
    "        dynamic_turn_angle = MAX_TURN_ANGLE - (speed_factor) * (MAX_TURN_ANGLE - MIN_TURN_ANGLE)\n",
    "        if action == 0:  # Left\n",
    "            car.angle += dynamic_turn_angle\n",
    "        elif action == 1:  # Right\n",
    "            car.angle -= dynamic_turn_angle\n",
    "    \n",
    "    if action == 2: # Brake\n",
    "        car.speed -= BRAKE_FORCE\n",
    "    \n",
    "    car.speed -= FRICTION\n",
    "    car.speed = max(0, min(car.speed, MAX_SPEED))\n",
    "    car.move()\n",
    "    \n",
    "    # --- GOAL-BASED REWARDS (Checkpoints and Crashing) ---\n",
    "    checkpoint_rects = [pygame.Rect(x, y, w, h) for x, y, w, h, a in checkpoint_data]\n",
    "    \n",
    "    # 5. Large reward for hitting a checkpoint.\n",
    "    if current_checkpoint < len(checkpoint_rects):\n",
    "        if car.rect.colliderect(checkpoint_rects[current_checkpoint]):\n",
    "            current_checkpoint += 1\n",
    "            reward += 200 # Large positive reward\n",
    "            print(f\"Checkpoint {current_checkpoint} reached!\")\n",
    "\n",
    "    # 6. Very large reward for finishing the lap.\n",
    "    if current_checkpoint == len(checkpoint_rects) and car.rect.colliderect(finish_line_rect):\n",
    "        reward += 1000\n",
    "        current_checkpoint = 0\n",
    "        print(\"Lap finished!\")\n",
    "\n",
    "    # 7. Large penalty for crashing.\n",
    "    try:\n",
    "        pixel_color = track_image.get_at((int(car.x), int(car.y)))[:3]\n",
    "        if pixel_color == DRAW_COLOR:\n",
    "            done = True\n",
    "    except IndexError:\n",
    "        done = True\n",
    "        \n",
    "    if done:\n",
    "        reward = -100 # Keep a significant penalty for crashing, but not as extreme as -100\n",
    "\n",
    "    new_state, _ = ray_casting(car, track_image)\n",
    "    return new_state, done, reward, current_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe761f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn(episodes=500):\n",
    "    \"\"\"\n",
    "    Main function to train the DQN agent with enhanced logging and plotting.\n",
    "    \"\"\"\n",
    "    pygame.init()\n",
    "    screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT)) # Keep commented out for speed\n",
    "    track_surface = pygame.image.load(TRACK_IMAGE_PATH).convert()\n",
    "    \n",
    "    ai_model = model()\n",
    "    agent = DQNAgent(ai_model)\n",
    "\n",
    "    # NEW: Add lists to store history for new plots\n",
    "    scores_history = []\n",
    "    loss_history = []\n",
    "    checkpoints_history = []\n",
    "    max_speed_history = []\n",
    "    \n",
    "    for e in range(episodes):\n",
    "        car = Car(CAR_IMAGE_PATH, DEFAULT_START_X, DEFAULT_START_Y, DEFAULT_START_ANGLE, DEFAULT_START_SPEED)\n",
    "        current_checkpoint = 0\n",
    "        \n",
    "        distances, _ = ray_casting(car, track_surface)\n",
    "        speed = car.speed / MAX_SPEED \n",
    "        state = np.array(distances + [speed]) \n",
    "        state = np.reshape(state, [1, 4])\n",
    "        \n",
    "        total_reward = 0\n",
    "        max_steps_per_episode = 2000\n",
    "        max_speed_episode = 0\n",
    "\n",
    "        for step in range(max_steps_per_episode):\n",
    "            action = agent.choose_action(state)\n",
    "            distances_next, done, reward, new_checkpoint = model_game_step(action, car, track_surface, current_checkpoint)\n",
    "            \n",
    "            max_speed_episode = max(max_speed_episode, car.speed)\n",
    "            \n",
    "            total_reward += reward\n",
    "            speed_next = car.speed / MAX_SPEED \n",
    "            next_state = np.array(distances_next + [speed_next])\n",
    "            next_state = np.reshape(next_state, [1, 4])\n",
    "            current_checkpoint = new_checkpoint\n",
    "            \n",
    "            agent.remember(state[0], action, reward, next_state[0], done)\n",
    "            state = next_state\n",
    "            \n",
    "            if step % 4 == 0: # Train every 8 steps for speed\n",
    "                loss = agent.train_from_memory()\n",
    "                if loss is not None:\n",
    "                    loss_history.append(loss)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        if e % 5 == 0:\n",
    "            agent.update_target_model()\n",
    "            print(f\"--- Target Network Updated at Episode {e+1} ---\")\n",
    "            \n",
    "        # NEW: Append the new metrics to their history lists\n",
    "        scores_history.append(total_reward)\n",
    "        checkpoints_history.append(current_checkpoint)\n",
    "        max_speed_history.append(max_speed_episode)\n",
    "        \n",
    "        print(\n",
    "            f\"Episode: {e+1}/{episodes}, \"\n",
    "            f\"Score: {total_reward:.2f}, \"\n",
    "            f\"Max Speed: {max_speed_episode:.2f}, \"\n",
    "            f\"Checkpoints: {current_checkpoint}, \"\n",
    "            f\"Epsilon: {agent.epsilon:.2f}\"\n",
    "        )\n",
    "\n",
    "        if (e + 1) % 50 == 0:\n",
    "            ai_model.save_weights(f\"dqn_car_weights_episode_{e+1}.weights.h5\")\n",
    "\n",
    "    pygame.quit()\n",
    "\n",
    "# --- MODIFIED: Enhanced plotting section with Bar Chart ---\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    \n",
    "    # NEW: Create 4 subplots instead of 3, and increase the figure size\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(12, 22)) \n",
    "\n",
    "    # --- Graph 1: Score ---\n",
    "    ax1.set_title('Agent Score Over Time')\n",
    "    ax1.set_xlabel('Episode')\n",
    "    ax1.set_ylabel('Total Reward (Score)')\n",
    "    ax1.plot(scores_history, label='Score per Episode', color='royalblue')\n",
    "    ax1.legend()\n",
    "\n",
    "    # --- Graph 2: Max Speed ---\n",
    "    ax2.set_title('Max Speed Achieved per Episode')\n",
    "    ax2.set_xlabel('Episode')\n",
    "    ax2.set_ylabel('Max Speed')\n",
    "    ax2.plot(max_speed_history, label='Max Speed', color='purple')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # --- Graph 3: Model Loss ---\n",
    "    ax3.set_title('Model Loss Over Time')\n",
    "    ax3.set_xlabel('Training Step')\n",
    "    ax3.set_ylabel('MSE Loss')\n",
    "    ax3.plot(loss_history, label='Training Loss', color='orangered', alpha=0.7)\n",
    "    ax3.legend()\n",
    "\n",
    "    # --- NEW: Graph 4: Checkpoints Bar Chart ---\n",
    "    ax4.set_title('Checkpoints Cleared per Episode')\n",
    "    ax4.set_xlabel('Episode')\n",
    "    ax4.set_ylabel('Checkpoints Cleared')\n",
    "    # Use ax4.bar() to create the bar chart\n",
    "    episodes = range(len(checkpoints_history))\n",
    "    ax4.bar(episodes, checkpoints_history, color='forestgreen', label='Checkpoints')\n",
    "    # Set y-axis to be integers since you can't clear half a checkpoint\n",
    "    ax4.yaxis.set_major_locator(plt.MaxNLocator(integer=True)) \n",
    "    ax4.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # --- Optional: Add a histogram for checkpoint distribution ---\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title('Distribution of Checkpoints Cleared')\n",
    "    plt.xlabel('Number of Checkpoints Cleared in an Episode')\n",
    "    plt.ylabel('Number of Episodes')\n",
    "    plt.hist(checkpoints_history, bins=range(max(checkpoints_history) + 2), align='left', rwidth=0.8)\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f3dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ai_simulation():\n",
    "    \"\"\"Runs the car simulation controlled by an AI model.\n",
    "        The AI model predicts actions based on the car's sensor data.\n",
    "        0: turn left\n",
    "        1: accelerate\n",
    "        2: turn right\n",
    "        3: brake\n",
    "    \"\"\"\n",
    "    pygame.init()\n",
    "    screen=pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "    clock=pygame.time.Clock()\n",
    "    pygame.display.set_caption(\"AI Car Simulation\")\n",
    "    track_surface=pygame.image.load(TRACK_IMAGE_PATH).convert()\n",
    "    car=Car(CAR_IMAGE_PATH,DEFAULT_START_X,DEFAULT_START_Y,DEFAULT_START_ANGLE,DEFAULT_START_SPEED)\n",
    "    font=pygame.font.SysFont(None,22)\n",
    "    \n",
    "    running=True\n",
    "    while running:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type==pygame.QUIT:\n",
    "                running=False\n",
    "        current_state,ray_endpoints=ray_casting(car,track_surface)\n",
    "        reshaped_state = np.reshape(current_state, [1, 3])\n",
    "        q_values = ai_model.predict(reshaped_state, verbose=0)\n",
    "        action = np.argmax(q_values[0])\n",
    "        _ ,_ ,done=model_game_step(action,car,track_surface)\n",
    "        if done:\n",
    "            text_surface = font.render(\"Car Crashed! Resetting...\", True, (255, 255, 255))\n",
    "            screen.blit(text_surface, (50, 50))\n",
    "            pygame.display.update()\n",
    "            pygame.time.wait(1000)\n",
    "            car=Car(CAR_IMAGE_PATH,DEFAULT_START_X,DEFAULT_START_Y,DEFAULT_START_ANGLE,DEFAULT_START_SPEED)\n",
    "        \n",
    "        screen.blit(track_surface,(0,0))\n",
    "        car.draw(screen)\n",
    "        \n",
    "        text_surface = font.render(f\"Distances: {current_state}\", True, (255, 255, 255))\n",
    "        screen.blit(text_surface, (50, 80))\n",
    "        for points in ray_endpoints:\n",
    "            pygame.draw.line(screen,(0,255,0),(car.x,car.y),points,1)\n",
    "            \n",
    "        pygame.display.update()\n",
    "        clock.tick(60)\n",
    "    pygame.quit()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e04541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(\n",
    "    start_x=DEFAULT_START_X,\n",
    "    start_y=DEFAULT_START_Y,\n",
    "    start_angle=DEFAULT_START_ANGLE,\n",
    "    start_speed=DEFAULT_START_SPEED\n",
    "):\n",
    "    \"\"\"Runs the car simulation manually by the user.\n",
    "\n",
    "    Args:\n",
    "        start_x (int, optional): The starting x-coordinate of the car. Defaults to DEFAULT_START_X.\n",
    "        start_y (int, optional): The starting y-coordinate of the car. Defaults to DEFAULT_START_Y.\n",
    "        start_angle (float, optional): The starting angle of the car. Defaults to DEFAULT_START_ANGLE.\n",
    "        start_speed (float, optional): The starting speed of the car. Defaults to DEFAULT_START_SPEED.\n",
    "    \"\"\"\n",
    "    pygame.init()\n",
    "    screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "    clock = pygame.time.Clock()\n",
    "    pygame.display.set_caption(\"Car Simulation\")\n",
    "\n",
    "    track_image = pygame.image.load(TRACK_IMAGE_PATH).convert()\n",
    "    track_surface = track_image.copy()\n",
    "\n",
    "    car = Car(CAR_IMAGE_PATH, start_x, start_y, start_angle, start_speed)\n",
    "\n",
    "    screen.fill(BG_COLOR)\n",
    "    screen.blit(track_image, (0, 0))\n",
    "\n",
    "    CAR_ROAD_COLOR = track_surface.get_at((start_x, start_y))[:3]\n",
    "\n",
    "  \n",
    "\n",
    "    lap_start_time=0\n",
    "    best_lap_time=float('inf')\n",
    "    current_lap_time=0\n",
    "    lap_started=False\n",
    "    car_on_finish=False\n",
    "\n",
    "    car_max_speed = 0\n",
    "    \n",
    "    #checkpoints\n",
    "    checkpoints=[]\n",
    "    \n",
    "    for x,y,w,h,a in checkpoint_data:\n",
    "        base_surface=pygame.Surface((w,h),pygame.SRCALPHA)\n",
    "        base_surface.fill((255,0,255,100))\n",
    "        rotated_surface=pygame.transform.rotate(base_surface,a)\n",
    "        rect=rotated_surface.get_rect(center=(x,y))\n",
    "        mask=pygame.mask.from_surface(rotated_surface)\n",
    "        checkpoints.append({'surface': rotated_surface, 'rect': rect, 'mask': mask})\n",
    "    current_checkpoint=0\n",
    "\n",
    "    running = True\n",
    "    while running:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "        keys = pygame.key.get_pressed()\n",
    "        if car.speed > 0:\n",
    "            car.speed -= FRICTION\n",
    "        if car.speed < 0:\n",
    "            car.speed += FRICTION\n",
    "        if abs(car.speed) < FRICTION:\n",
    "            car.speed = 0\n",
    "        if keys[pygame.K_DOWN]:\n",
    "            car.speed -= BRAKE_FORCE\n",
    "        if keys[pygame.K_UP]:\n",
    "            if car.speed < MAX_SPEED:\n",
    "                car.speed += ACCELERATION\n",
    "                \n",
    "        if car.speed > 0.1:\n",
    "            speed_factor = car.speed / MAX_SPEED\n",
    "            turn_range = MAX_TURN_ANGLE - MIN_TURN_ANGLE\n",
    "            dynamic_turn_angle = MAX_TURN_ANGLE - (speed_factor * turn_range)\n",
    "        \n",
    "            if keys[pygame.K_LEFT]:\n",
    "                car.angle += dynamic_turn_angle\n",
    "            if keys[pygame.K_RIGHT]:\n",
    "                car.angle -= dynamic_turn_angle\n",
    "\n",
    "        screen.blit(track_image, (0, 0))\n",
    "\n",
    "        font = pygame.font.Font(None, 22)\n",
    "        text_surface = font.render(f\"Speed: {car.speed:.2f}\", True, (255, 255, 255))\n",
    "        screen.blit(text_surface, (50, 50))\n",
    "\n",
    "        # Ray casting\n",
    "        distance, sensor_endpoint = ray_casting(car, track_surface)\n",
    "        text_surface = font.render(f\"Distances: {distance}\", True, (255, 255, 255))\n",
    "        screen.blit(text_surface, (50, 80))\n",
    "        for endpoint in sensor_endpoint:\n",
    "            pygame.draw.line(screen, (0, 255, 0), (car.x, car.y), endpoint, 1)\n",
    "\n",
    "        car.move()\n",
    "        \n",
    "        #cheking checkpoints\n",
    "        if current_checkpoint < len(checkpoints):\n",
    "            target = checkpoints[current_checkpoint]\n",
    "\n",
    "            # compute offset of target mask relative to car mask\n",
    "            offset_x = target['rect'].left - car.rect.left\n",
    "            offset_y = target['rect'].top  - car.rect.top\n",
    "\n",
    "\n",
    "            if (offset_y==0 and -60<offset_x<60) or (offset_x==0 and -60<offset_y<60):\n",
    "                current_checkpoint += 1\n",
    "                print(f\"Checkpoint reached! {current_checkpoint}\")\n",
    "\n",
    "        \n",
    "        car.draw(screen)\n",
    "        \n",
    "        for i, cp in enumerate(checkpoints):\n",
    "          screen.blit(cp['surface'], cp['rect'])\n",
    "          if i == current_checkpoint:\n",
    "              pygame.draw.rect(screen, (0, 255, 0), cp['rect'], 3)\n",
    "        \n",
    "        #lap timing (collision detection)\n",
    "        is_colliding=car.get_rect().colliderect(finish_line_rect)\n",
    "        if is_colliding and not car_on_finish:\n",
    "            car_on_finish=True\n",
    "            if lap_started and current_checkpoint == len(checkpoints):\n",
    "                lap_time=time.time()-lap_start_time\n",
    "                best_lap_time=min(best_lap_time,lap_time)\n",
    "                lap_start_time=time.time()\n",
    "                current_checkpoint=0\n",
    "            elif not lap_started:\n",
    "                lap_started = True\n",
    "                lap_start_time = time.time()\n",
    "                current_checkpoint = 0\n",
    "        if not is_colliding:\n",
    "            car_on_finish=False\n",
    "            \n",
    "        pygame.draw.rect(screen, (250, 100, 50), finish_line_rect)\n",
    "        \n",
    "\n",
    "        # Collision detection (including out-of-bounds)\n",
    "        crashed = False\n",
    "        car_center_pos = (int(car.x), int(car.y))\n",
    "        if not (0 <= car.x < SCREEN_WIDTH and 0 <= car.y < SCREEN_HEIGHT):\n",
    "            crashed = True\n",
    "        else:\n",
    "            try:\n",
    "                pixel_color = track_surface.get_at(car_center_pos)[:3]\n",
    "                if pixel_color != CAR_ROAD_COLOR:\n",
    "                    crashed = True\n",
    "            except IndexError:\n",
    "                crashed = True\n",
    "\n",
    "        if crashed:\n",
    "            lap_started=False\n",
    "            current_lap_time=0 \n",
    "            current_checkpoint=0\n",
    "            text_surface = font.render(\"Car has crashed!\", True, (255, 255, 255))\n",
    "            screen.blit(text_surface, (50, 110))\n",
    "            pygame.display.update()\n",
    "            pygame.time.wait(1000)  # Show message for 1 second\n",
    "            car.x, car.y = start_x, start_y\n",
    "            car.angle = start_angle\n",
    "            car.speed = start_speed\n",
    "\n",
    "        if car.speed > car_max_speed:\n",
    "            car_max_speed = car.speed\n",
    "\n",
    "        if lap_started:\n",
    "            current_lap_time = time.time() - lap_start_time\n",
    "            current_lap_str = f\"Lap: {current_lap_time:.2f}s\"\n",
    "        else:\n",
    "            current_lap_str = \"Lap: 0.00s\"                                           \n",
    "        best_lap_str = f\"Best: {best_lap_time:.2f}s\" if best_lap_time != float('inf') else \"Best: N/A\"\n",
    "        text_surface = font.render(current_lap_str, True, (255, 255, 255))            \n",
    "        screen.blit(text_surface, (50, 500))\n",
    "        best_text = font.render(best_lap_str, True, (255, 255, 255))\n",
    "        screen.blit(best_text, (50, 530))\n",
    "        text_surface = font.render(f\"Max speed: {car_max_speed:.2f}\", True, (255, 255, 255))\n",
    "        screen.blit(text_surface, (50, 470))\n",
    "\n",
    "        pygame.display.update()\n",
    "        clock.tick(60)\n",
    "\n",
    "    pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07ea071",
   "metadata": {},
   "source": [
    "        if event.type == pygame.MOUSEMOTION:\n",
    "            mouse_point = event.pos\n",
    "            text_surface = font.render(f\"Location: {mouse_point}\", True, (255, 255, 255))\n",
    "            screen.blit(text_surface, (50, 100))\n",
    " #code for getting mouse location\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823c5ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #draw_track()\n",
    "    #run_simulation()\n",
    "    # run_ai_simulation()\n",
    "    train_dqn(episodes=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b164f920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded weights from: dqn_car_weights_episode_50c.weights.h5\n"
     ]
    }
   ],
   "source": [
    "# --- IMPORTS AND SETUP FOR THE VISUAL SIMULATION ---\n",
    "# Note: We need to re-import and set up a few things in a new cell.\n",
    "# import pygame\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# import time\n",
    "# import os\n",
    "\n",
    "# This ensures the Pygame window appears correctly in a new run.\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"windows\" \n",
    "\n",
    "\n",
    "# --- MAIN SIMULATION FUNCTION ---\n",
    "def run_trained_agent(weights_path):\n",
    "    \"\"\"\n",
    "    Loads a trained agent and runs the visual simulation with corrected logic.\n",
    "    \"\"\"\n",
    "    pygame.init()\n",
    "    screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "    clock = pygame.time.Clock()\n",
    "    pygame.display.set_caption(\"Trained AI Agent\")\n",
    "    font = pygame.font.SysFont(None, 36)\n",
    "    crash_font = pygame.font.SysFont(None, 72)\n",
    "    track_surface = pygame.image.load(TRACK_IMAGE_PATH).convert()\n",
    "\n",
    "    ai_model = model()\n",
    "    try:\n",
    "        ai_model.load_weights(weights_path)\n",
    "        print(f\"Successfully loaded weights from: {weights_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading weights: {e}\")\n",
    "        pygame.quit()\n",
    "        return\n",
    "    action_counts = {0: 0, 1: 0, 2: 0}  # To track the number of each action taken\n",
    "    car = Car(CAR_IMAGE_PATH, DEFAULT_START_X, DEFAULT_START_Y, angle=DEFAULT_START_ANGLE)\n",
    "    running = True\n",
    "    while running:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "\n",
    "        # 1. Get state (Corrected to use 4 inputs)\n",
    "        distances, ray_endpoints = ray_casting(car, track_surface)\n",
    "        normalized_speed = car.speed / MAX_SPEED\n",
    "        state = np.array(distances + [normalized_speed])\n",
    "        state = np.reshape(state, [1, 4])\n",
    "        # 2. Predict the best action\n",
    "        q_values = ai_model.predict(state, verbose=0)\n",
    "        action = np.argmax(q_values[0])\n",
    "        action_map = {0: \"Left\", 1: \"Right\", 2: \"Brake\"}\n",
    "        action_counts[action] += 1\n",
    "        # 3. Execute action (using the same physics as the training function)\n",
    "        car.speed += ACCELERATION\n",
    "        if car.speed > 0:\n",
    "            speed_factor = car.speed / MAX_SPEED\n",
    "            dynamic_turn_angle = MAX_TURN_ANGLE - (speed_factor) * (MAX_TURN_ANGLE - MIN_TURN_ANGLE)\n",
    "            if action == 0: car.angle += dynamic_turn_angle\n",
    "            elif action == 1: car.angle -= dynamic_turn_angle\n",
    "        if action == 2: car.speed -= BRAKE_FORCE\n",
    "        \n",
    "        car.speed -= FRICTION\n",
    "        car.speed = max(0, min(car.speed, MAX_SPEED))\n",
    "        car.move()\n",
    "\n",
    "        # 4. Check for crash (Corrected to use BG_COLOR)\n",
    "        crashed = False\n",
    "        try:\n",
    "            pixel_color = track_surface.get_at((int(car.x), int(car.y)))[:3]\n",
    "            if pixel_color == DRAW_COLOR:\n",
    "                crashed = True\n",
    "        except IndexError:\n",
    "            crashed = True\n",
    "        \n",
    "        if crashed:\n",
    "            crash_text = crash_font.render(\"CRASHED! Resetting...\", True, (255, 0, 0))\n",
    "            text_rect = crash_text.get_rect(center=(SCREEN_WIDTH/2, SCREEN_HEIGHT/2))\n",
    "            screen.blit(crash_text, text_rect)\n",
    "            pygame.display.update()\n",
    "            pygame.time.wait(2000)\n",
    "            car = Car(CAR_IMAGE_PATH, DEFAULT_START_X, DEFAULT_START_Y, angle=DEFAULT_START_ANGLE)\n",
    "            print(\"Total actions taken by the agent during the simulation:\")\n",
    "            for action, count in action_counts.items():\n",
    "                print(f\"Action {action}: {count}\")\n",
    "            action_counts = {0: 0, 1: 0, 2: 0}\n",
    "            \n",
    "        # 5. Render everything\n",
    "        screen.blit(track_surface, (0, 0))\n",
    "        car.draw(screen)\n",
    "        for point in ray_endpoints:\n",
    "            pygame.draw.line(screen, (0, 255, 0), (car.x, car.y), point, 1)\n",
    "        \n",
    "        info_text = f\"Action: {action_map[action]} | Speed: {car.speed:.2f}\"\n",
    "        text_surface = font.render(info_text, True, (255, 255, 255))\n",
    "        screen.blit(text_surface, (20, 20))\n",
    "\n",
    "        pygame.display.update()\n",
    "        clock.tick(60)\n",
    "\n",
    "    pygame.quit()   \n",
    "# --- RUN THE SIMULATION WITH YOUR TRAINED WEIGHTS ---\n",
    "# ------------------------------------------------------------------\n",
    "# IMPORTANT: Change this to the name of your saved weights file!\n",
    "WEIGHTS_FILENAME = \"dqn_car_weights_episode_50c.weights.h5\"\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# This checks if a pygame window is already open to avoid errors\n",
    "if not pygame.display.get_init():\n",
    "    run_trained_agent(WEIGHTS_FILENAME)\n",
    "else:\n",
    "    # If you get this message, restart the notebook kernel before running this cell again.\n",
    "    print(\"Pygame window may already be open. Please restart the kernel to run again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3bfbe8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading weights: A total of 3 objects could not be loaded. Example error message for object <Dense name=dense_3, built=True>:\n",
      "\n",
      "Layer 'dense_3' expected 2 variables, but received 0 variables during loading. Expected: ['kernel', 'bias']\n",
      "\n",
      "List of objects that could not be loaded:\n",
      "[<Dense name=dense_3, built=True>, <Dense name=dense_4, built=True>, <Dense name=dense_5, built=True>]\n",
      "Please ensure the weights file exists and matches the model architecture.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yash\\OneDrive\\Desktop\\Neural Networks Car Project\\.venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 0 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# --- IMPORTS AND SETUP FOR THE VISUAL SIMULATION ---\n",
    "# Note: We need to re-import and set up a few things in a new cell.\n",
    "# import pygame\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# import time\n",
    "# import os\n",
    "\n",
    "# This ensures the Pygame window appears correctly in a new run.\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"windows\" \n",
    "\n",
    "\n",
    "# --- MAIN SIMULATION FUNCTION ---\n",
    "def run_trained_agent(weights_path):\n",
    "    \"\"\"\n",
    "    Loads a trained agent and runs the visual simulation with a crash delay.\n",
    "    \"\"\"\n",
    "    pygame.init()\n",
    "    screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "    clock = pygame.time.Clock()\n",
    "    pygame.display.set_caption(\"Trained AI Agent\")\n",
    "    font = pygame.font.SysFont(None, 36)\n",
    "    crash_font = pygame.font.SysFont(None, 72) # Font for the crash message\n",
    "    track_surface = pygame.image.load(TRACK_IMAGE_PATH).convert()\n",
    "\n",
    "    # Create and load the model\n",
    "    # This assumes your model() function is defined in a cell above\n",
    "    ai_model = model() \n",
    "    try:\n",
    "        ai_model.load_weights(weights_path)\n",
    "        print(f\"Successfully loaded weights from: {weights_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading weights: {e}\")\n",
    "        print(\"Please ensure the weights file exists and matches the model architecture.\")\n",
    "        pygame.quit()\n",
    "        return\n",
    "\n",
    "    # This assumes your Car class and ray_casting function are defined above\n",
    "    car = Car(CAR_IMAGE_PATH, DEFAULT_START_X, DEFAULT_START_Y, angle=DEFAULT_START_ANGLE)\n",
    "    running = True\n",
    "    while running:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "\n",
    "        # 1. Get state\n",
    "        distances, ray_endpoints = ray_casting(car, track_surface)\n",
    "        normalized_speed = car.speed / MAX_SPEED\n",
    "        state = np.array(distances + [normalized_speed])\n",
    "        state = np.reshape(state, [1, 4])\n",
    "\n",
    "        # 2. Predict the best action\n",
    "        q_values = ai_model.predict(state, verbose=0)\n",
    "        action = np.argmax(q_values[0])\n",
    "        action_map = {0: \"Left\", 1: \"Right\", 2: \"Brake\"}\n",
    "\n",
    "        # 3. Execute the action\n",
    "        car.speed += ACCELERATION\n",
    "        if car.speed > 0:\n",
    "            speed_factor = car.speed / MAX_SPEED\n",
    "            dynamic_turn_angle = MAX_TURN_ANGLE - (speed_factor) * (MAX_TURN_ANGLE - MIN_TURN_ANGLE)\n",
    "            if action == 0:  # Left\n",
    "                car.angle += dynamic_turn_angle\n",
    "            elif action == 1:  # Right\n",
    "                car.angle -= dynamic_turn_angle\n",
    "        if action == 2:  # Brake\n",
    "            car.speed -= BRAKE_FORCE\n",
    "        \n",
    "        car.speed -= FRICTION\n",
    "        car.speed = max(0, min(car.speed, MAX_SPEED))\n",
    "        car.move()\n",
    "\n",
    "        # 4. Check for crash\n",
    "        crashed = False\n",
    "        try:\n",
    "            pixel_color = track_surface.get_at((int(car.x), int(car.y)))[:3]\n",
    "            if pixel_color == DRAW_COLOR:\n",
    "                crashed = True\n",
    "        except IndexError:\n",
    "            crashed = True\n",
    "        \n",
    "        # Crash handling with on-screen message and delay\n",
    "        if crashed:\n",
    "            crash_text = crash_font.render(\"CRASHED! Resetting...\", True, (255, 0, 0))\n",
    "            text_rect = crash_text.get_rect(center=(SCREEN_WIDTH/2, SCREEN_HEIGHT/2))\n",
    "            screen.blit(crash_text, text_rect)\n",
    "            pygame.display.update()\n",
    "            pygame.time.wait(2000) # Wait for 2 seconds\n",
    "            car = Car(CAR_IMAGE_PATH, DEFAULT_START_X, DEFAULT_START_Y, angle=DEFAULT_START_ANGLE)\n",
    "            \n",
    "        # 5. Render everything\n",
    "        screen.blit(track_surface, (0, 0))\n",
    "        car.draw(screen)\n",
    "        for point in ray_endpoints:\n",
    "            pygame.draw.line(screen, (0, 255, 0), (car.x, car.y), point, 1)\n",
    "        \n",
    "        info_text = f\"Action: {action_map[action]} | Speed: {car.speed:.2f}\"\n",
    "        text_surface = font.render(info_text, True, (255, 255, 255))\n",
    "        screen.blit(text_surface, (20, 20))\n",
    "\n",
    "        pygame.display.update()\n",
    "        clock.tick(60)\n",
    "\n",
    "    pygame.quit()\n",
    "\n",
    "# --- RUN THE SIMULATION WITH YOUR TRAINED WEIGHTS ---\n",
    "# ------------------------------------------------------------------\n",
    "# IMPORTANT: Change this to the name of your saved weights file!\n",
    "WEIGHTS_FILENAME = \"dqn_car_weights_episode_50a.weights.h5\"\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# This checks if a pygame window is already open to avoid errors\n",
    "if not pygame.display.get_init():\n",
    "    run_trained_agent(WEIGHTS_FILENAME)\n",
    "else:\n",
    "    # If you get this message, restart the notebook kernel before running this cell again.\n",
    "    print(\"Pygame window may already be open. Please restart the kernel to run again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a12d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"--- RUNNING VISUAL SANITY CHECK ---\")\n",
    "    \n",
    "    # 1. Setup the environment\n",
    "    pygame.init()\n",
    "    screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "    track_surface = pygame.image.load(TRACK_IMAGE_PATH).convert()\n",
    "    \n",
    "    # 2. Place the car at its starting position\n",
    "    car = Car(CAR_IMAGE_PATH, DEFAULT_START_X, DEFAULT_START_Y, DEFAULT_START_ANGLE, DEFAULT_START_SPEED)\n",
    "\n",
    "    # 3. Draw the initial state\n",
    "    screen.blit(track_surface, (0, 0))\n",
    "    car.draw(screen)\n",
    "    pygame.display.update()\n",
    "    \n",
    "    print(f\"Initial Car Position: ({car.x:.2f}, {car.y:.2f})\")\n",
    "    print(\"Is the car on the track? Look at the screen.\")\n",
    "    time.sleep(5) # PAUSE FOR 5 SECONDS TO LET YOU SEE\n",
    "\n",
    "    # 4. Take ONE random action\n",
    "    action = random.randrange(3)\n",
    "    print(f\"\\nTaking ONE random action: {['Left', 'Right', 'Brake'][action]}\")\n",
    "    _, done, _, _ = model_game_step(action, car, track_surface, 0)\n",
    "\n",
    "    # 5. Draw the state AFTER one move\n",
    "    screen.blit(track_surface, (0, 0))\n",
    "    car.draw(screen)\n",
    "    pygame.display.update()\n",
    "\n",
    "    print(f\"Position after one move: ({car.x:.2f}, {car.y:.2f})\")\n",
    "    print(f\"Did it crash? (done = {done})\")\n",
    "    if done:\n",
    "        print(\"\\n>>> TEST FAILED: The car crashed on its very first move!\")\n",
    "    else:\n",
    "        print(\"\\n>>> TEST PASSED: The car survived its first move.\")\n",
    "\n",
    "    time.sleep(5) # PAUSE AGAIN\n",
    "    pygame.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
